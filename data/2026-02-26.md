<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.CR](#cs.CR) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Disaster Question Answering with LoRA Efficiency and Accurate End Position](https://arxiv.org/abs/2602.21212)
*Takato Yasuno*

Main category: cs.CL

TL;DR: 本文提出了一种基于日本灾害情境的灾害问答系统，采用cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads架构，通过LoRA优化实现高效参数利用，在灾害响应场景中达到实用精度。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生频率低且影响范围有限，个人面临灾害时缺乏领域知识和经验。现有RAG搜索和大型语言模型难以保证获取相关灾害知识和类似情境经验，且幻觉可能导致虚假信息传播加剧混乱。

Method: 采用cl-tohoku/bert-base-japanese-v3预训练模型，结合Bi-LSTM增强上下文理解，使用Enhanced Position Heads架构，并通过LoRA（Low-Rank Adaptation）进行效率优化，仅使用总参数的5.7%（6.7M/117M）。

Result: 系统达到70.4%的End Position准确率和0.885的Span F1分数，证明日本BERT-base优化与Bi-LSTM上下文理解的组合在真实灾害响应场景中达到适用精度水平。

Conclusion: 该灾害问答系统在效率和准确性方面表现良好，适合灾害响应场景。未来挑战包括：建立自然灾害问答基准数据集、用灾害知识微调基础模型、开发轻量级边缘AI灾害问答应用以应对灾害期间电力通信不足的情况，以及解决灾害知识库更新和持续学习能力问题。

Abstract: Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\% End Position accuracy with only 5.7\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.

</details>


### [2] [Inference-time Alignment via Sparse Junction Steering](https://arxiv.org/abs/2602.21215)
*Runyi Hu,Jie Zhang,Shiqian Zhao,Jiale Meng,Jiwei Li,Jason Zeng,Ming Wu,Michael Heinrich,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: SIA（稀疏推理时对齐）通过在关键决策点进行稀疏干预，仅对20%-80%的token进行引导，实现了比密集干预更好的对齐效果与计算效率平衡。


<details>
  <summary>Details</summary>
Motivation: 现有token级引导方法在每个解码步骤都进行密集干预，导致计算开销大且可能过度偏离模型固有分布，损害生成质量。研究表明密集干预并非必要，关键决策点的稀疏干预更为有效。

Method: 提出SIA（稀疏推理时对齐）方法，仅在高熵连接点（关键决策点）进行干预。这些点标记生成轨迹中的关键决策，对错位特别敏感，需要引入对齐相关的奖励信号。方法可与Best-of-N等搜索方法无缝集成。

Result: 实验表明，仅对20%-80%的token进行引导即可实现优越的对齐效率权衡。对于Qwen3等强基础模型，仅干预20%的token即可匹配甚至超越经过大量后训练的指令模型。稀疏性使计算成本降低高达6倍，同时保持更好的模型原生分布。

Conclusion: 稀疏推理时对齐是一种高效且有效的token级引导方法，通过在关键决策点进行干预，实现了更好的对齐效果、计算效率和分布保持的平衡，为推理时对齐提供了新的研究方向。

Abstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.

</details>


### [3] [EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning](https://arxiv.org/abs/2602.21216)
*Zhyar Rzgar K Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 该研究通过微调通用和领域特定的预训练语言模型，并结合scispaCy提取的生物医学实体信息，开发了用于自动检测EQ-5D相关文献的模型，显著提高了系统文献综述的效率。


<details>
  <summary>Details</summary>
Motivation: 在健康经济学中，系统文献综述依赖正确识别使用EQ-5D工具的出版物，但手动筛选大量科学文献耗时、易出错且不一致，需要自动化解决方案来提高效率和准确性。

Method: 研究采用九种实验设置，结合三种scispaCy模型（提取生物医学实体信息）和三种预训练语言模型（BERT、SciBERT、BioBERT），在句子和文献级别进行评估。同时探索了多实例学习方法，通过注意力池化将句子级信息聚合为文献级预测。

Result: 实验结果显示F1分数达到0.82，文献级召回率接近完美，显著超过传统的词袋模型基线和近期报道的预训练语言模型基线。实体信息增强显著改善了领域适应性和模型泛化能力。

Conclusion: 实体信息增强的预训练语言模型能够有效提高EQ-5D检测的准确性，为系统文献综述中的自动化筛选提供了更可靠的解决方案，显著提升了领域适应性和模型性能。

Abstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.

</details>


### [4] [Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention](https://arxiv.org/abs/2602.21217)
*S M Ruhul Alam,Rifa Ferzana*

Main category: cs.CL

TL;DR: 提出应用社会语言学AI促进社区发展(ASA-CD)新范式，通过语言分析和AI干预解决社区问题，包含语言生物标志物、发展导向NLP和五阶段干预协议。


<details>
  <summary>Details</summary>
Motivation: 传统AI方法在解决社区发展问题时缺乏语言层面的系统性分析框架，需要建立既能识别社区话语分裂又能促进集体成果的AI干预范式。

Method: 提出ASA-CD三要素：1)语言生物标志物作为话语分裂的计算指标；2)发展导向自然语言处理，优先考虑集体成果的AI优化范式；3)标准化五阶段话语干预协议。通过真实世界和合成语料库进行概念验证研究。

Result: 概念验证研究表明排他性语言与负面情感存在系统性关联，并模拟了基于干预的改善效果。ASA-CD为可扩展、价值对齐的AI提供了统一的方法论、伦理和实证框架。

Conclusion: ASA-CD建立了服务于社区赋能的AI新范式，通过语言分析、发展导向优化和标准化干预协议，为解决社区挑战提供了系统性框架。

Abstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.

</details>


### [5] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: EPSVec：一种基于差分隐私的轻量级文本生成方法，通过数据集向量引导LLM生成，将隐私预算与生成过程解耦，在低数据场景下仍能保持高质量


<details>
  <summary>Details</summary>
Motivation: 高质量数据对机器学习至关重要，但许多有价值的数据集因敏感性无法自由共享。现有隐私文本生成方法效率低下：数据密集、计算缓慢，通常需要大量私有语料或批量大小才能达到可用质量

Method: 提出EPSVec方法，使用数据集向量（激活空间中捕捉私有数据与公共先验分布差异的方向）引导LLM生成。该方法仅需一次性提取和净化引导向量，然后进行标准解码，将隐私预算与生成过程解耦。同时利用预训练基础模型和固定样本提示来提升生成多样性和保真度

Result: 实验表明EPSVec在分布对齐和下游任务效用方面优于现有基线方法，特别是在低数据场景下表现突出，同时显著减少了计算开销

Conclusion: EPSVec提供了一种高效、轻量级的差分隐私文本生成解决方案，能够在保护隐私的同时生成高质量的合成数据，特别适用于数据稀缺场景

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [6] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: GraSPer是一个基于图的稀疏个性化推理框架，通过预测未来可能交互的项目并生成相应文本来增强稀疏用户上下文，从而提升LLM个性化生成效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中用户通常只有稀疏的交互历史（如冷启动用户、新注册客户），这限制了LLM基于个性化上下文的生成能力，需要解决稀疏上下文下的个性化文本生成问题。

Method: GraSPer框架包含三个步骤：1）通过预测用户未来可能交互的项目来增强用户上下文；2）通过推理对齐为这些交互生成文本以丰富增强的上下文；3）基于真实和合成的历史记录生成个性化输出，确保与用户风格和偏好对齐。

Result: 在三个基准个性化生成数据集上的广泛实验表明，GraSPer取得了显著的性能提升，在稀疏用户上下文设置下大幅改善了个性化效果。

Conclusion: GraSPer通过图基增强和推理对齐有效解决了稀疏用户上下文下的LLM个性化生成问题，为冷启动用户和新用户提供了有效的个性化解决方案。

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [7] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 提出基于场论的AI智能体记忆系统，将记忆视为连续场而非离散数据库条目，通过偏微分方程控制记忆在语义空间中的扩散、衰减和耦合，在长上下文基准测试中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统AI智能体记忆系统通常采用离散数据库结构，难以有效处理长期、连续的交互信息。受经典场论启发，研究者希望开发一种更自然的记忆表示方法，能够模拟记忆在语义空间中的连续演化过程，从而更好地支持多轮对话和多会话推理任务。

Method: 提出场论记忆系统，将存储信息视为由偏微分方程控制的连续场。记忆在语义空间中扩散，基于重要性进行热力学衰减，在多智能体场景中通过场耦合实现交互。系统在两个长上下文基准上进行评估：LoCoMo（ACL 2024）包含35个会话的300轮对话，以及LongMemEval（ICLR 2025）测试500+轮的多会话推理。

Result: 在LongMemEval基准测试中，场论方法取得显著改进：多会话推理F1分数提升116%（p<0.01，d=3.06），时序推理提升43.8%（p<0.001，d=9.21），知识更新检索召回率提升27.8%（p<0.001，d=5.00）。多智能体实验通过场耦合实现了接近完美的集体智能（>99.8%）。

Conclusion: 场论记忆系统为AI智能体提供了一种新颖且有效的记忆表示方法，通过连续场模型显著提升了长上下文理解和多会话推理能力，在多智能体协作中展现出强大的集体智能潜力，为未来智能体记忆系统设计提供了新方向。

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [8] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 提出基于向量数据库检索的动态LoRA适配器组合框架，通过检索相似训练示例实现零样本多任务泛化，无需额外训练检索器或全模型微调。


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效微调方法虽然能实现大语言模型的任务特定适配，但如何高效组合多个专用适配器来处理未见任务仍具挑战性。现有方法难以实现零样本跨任务泛化。

Method: 构建任务感知向量数据库，嵌入22个数据集的训练示例；推理时检索最相似训练示例，通过nucleus采样计算任务相似度分布，使用检索加权融合策略动态合并相关LoRA适配器；评估了Linear、Concatenation、TIES和Magnitude Prune四种合并方法。

Result: 数据集中心的检索方法常匹配或超越单独微调的任务特定适配器性能。Linear合并方法在PIQA上达到70.95%，在RTE上达到77.62%，显著优于单任务基线（分别为46%和52%）。框架无需额外检索器训练，使用冻结嵌入，实现高效可解释的适配器组合。

Conclusion: 基于检索的动态合并为可扩展的参数高效多任务学习提供了有前景的方向，无需为每个新任务进行全模型重新训练，实现了零样本跨任务泛化能力。

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [9] [Measuring Pragmatic Influence in Large Language Model Instructions](https://arxiv.org/abs/2602.21223)
*Yilin Geng,Omri Abend,Eduard Hovy,Lea Frermann*

Main category: cs.CL

TL;DR: 研究LLM指令跟随中的语用框架效应：通过分离任务内容与框架提示，量化分析400种框架策略如何系统性地影响模型对指令的优先级判断


<details>
  <summary>Details</summary>
Motivation: 现有研究多将语用框架（如"这很紧急"、"作为你的上司"等提示语）视为提示优化工具或安全漏洞，但缺乏对其作为指令跟随系统可测量属性的系统性研究。需要建立框架来隔离和量化这些上下文线索对LLM行为的影响

Method: 提出包含三个创新组件的框架：1) 指令-框架分解，分离框架上下文与任务规范；2) 包含13种策略、4个机制簇的400种框架实例分类法；3) 基于优先级的测量方法，通过观察指令优先级偏移来量化影响

Result: 在五个不同家族和规模的LLM上，影响机制导致指令优先级的一致性和结构化偏移，使模型从基线中立性转向偏向框架化的指令。语用框架对模型行为产生可预测的系统性影响

Conclusion: 本研究确立了语用框架作为指令跟随系统中可测量和可预测的因素，为理解LLM如何解释和响应人类指令提供了新的分析框架和量化方法

Abstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like "This is urgent" or "As your supervisor" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.

</details>


### [10] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 提出一种将推测解码中被丢弃的草稿转换为可重用令牌的新系统，通过隐藏状态级别的自回归预测和延迟令牌信息集成，实现计算浪费的回收，相比标准推测解码获得最高3.3倍加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码虽然通过轻量级草稿模型并行验证提高了内存受限推理的算术强度，但大多数草稿令牌验证失败被丢弃，导致显著的计算效率低下。研究旨在回收这些浪费的计算。

Method: 1) 基于自回归隐藏状态的草稿模型架构，保留比基于令牌的草稿更丰富的语义以促进草稿重用；2) 高效的令牌信息注入机制，利用专用草稿模型构建高质量草稿令牌树并支持从验证失败中重新采样令牌；3) 消除设计中的隐藏开销以最大化硬件利用率。

Result: 通过广泛评估，相比各种基线方法，该系统实现了最高3.3倍的加速，显著优于标准推测解码。

Conclusion: 通过将丢弃的草稿转换为可重用令牌，提出的系统有效回收了推测解码中的计算浪费，显著提高了LLM推理的计算效率，为加速推理提供了新思路。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [11] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 渐进式数据调度（一种课程学习策略）在文档理解模型中能稳定减少约33%的训练时间，其效率增益主要源于数据量减少而非顺序安排，课程特定收益取决于模型容量与任务复杂度的交互。


<details>
  <summary>Details</summary>
Motivation: 研究渐进式数据调度（逐步增加训练数据暴露：33%→67%→100%）是否能在架构不同的文档理解模型中产生一致的效率增益，并探究课程学习效应与单纯计算减少的区别。

Method: 使用BERT（纯文本，1.1亿参数）和LayoutLMv3（多模态，1.26亿参数）在FUNSD和CORD基准上评估渐进式调度。引入匹配计算基线（Standard-7）控制总梯度更新以隔离课程效应。进行调度消融实验比较渐进式、两阶段、反向和随机调度。

Result: 渐进式调度减少约33%的训练时间（从6.67到10.0有效epoch当量）。在FUNSD上，课程显著优于匹配计算基线（BERT：ΔF1=+0.023，p=0.022，dz=3.83），表明容量受限模型存在真正的调度收益；但LayoutLMv3无类似收益（p=0.621）。在CORD上，所有条件收敛到相同F1分数（≥0.947）。调度消融表明效率增益源于数据量减少而非顺序安排。

Conclusion: 渐进式调度是跨模型族的可靠计算减少策略，其课程特定收益取决于模型容量与任务复杂度的交互：容量受限模型（如BERT）能从课程学习中获益，而具有足够归纳偏置的多模态模型（如LayoutLMv3）或简单任务则无额外收益。

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [12] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 伊斯兰法律基准测试显示当前大语言模型在伊斯兰法学推理方面存在严重缺陷，最佳模型正确率仅68%，幻觉率21%，表明基于提示的方法无法弥补基础知识的缺失。


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林使用GPT、Claude和DeepSeek等大语言模型寻求宗教指导，需要评估这些AI系统能否可靠地进行伊斯兰法律推理。目前缺乏系统性的评估框架来衡量AI在伊斯兰法学领域的表现。

Method: 引入IslamicLegalBench，首个评估大语言模型在七个伊斯兰法学派别表现的基准测试，包含718个实例，涵盖13个不同复杂度的任务。评估了九个最先进的模型，使用少量样本提示进行测试。

Result: 评估结果显示重大局限性：最佳模型仅达到68%正确率，21%幻觉率；多个模型正确率低于35%，幻觉率超过55%。少量样本提示仅对2/9模型有>1%的改进。中等复杂度任务错误率最高，而高复杂度任务通过语义推理表现出表面能力。虚假前提检测显示危险的顺从性，6/9模型接受误导性假设的比率超过40%。

Conclusion: 基于提示的方法无法弥补缺失的基础知识。IslamicLegalBench提供了首个评估AI伊斯兰法律推理的系统框架，揭示了日益依赖精神指导工具中的关键差距。当前大语言模型在伊斯兰法学推理方面不可靠，需要更专业的知识基础。

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [13] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 论文提出了一种预算感知的智能体路由方法，通过在每个步骤中选择廉价或昂贵模型来优化成本-成功率边界，并在严格的任务预算下运行。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型发展为执行长期工作流的自主智能体，在每个步骤都调用高能力模型在经济上不可持续。现有的模型路由方法适用于单轮查询，但智能体路由是顺序性、路径依赖的问题：早期错误会累积，反馈通常在任务结束时才出现，且部署通常要求严格的任务预算限制。

Method: 提出边界引导训练方法，利用两种边界策略（始终使用小模型 vs. 始终使用大模型）构建难度分类，并在稀疏奖励下锚定学习。通过分层采样成本效益轨迹进行边界引导的SFT数据合成预热，然后应用边界引导策略优化（BoPO），结合边界相对奖励和参考引导优势来避免退化的廉价失败解决方案。

Result: 实验结果表明，该方法改进了效率边界，以显著更低的成本匹配强大的路由基线，同时展示了在严格推理时预算约束下的泛化能力。

Conclusion: 该工作为智能体路由建立了基础框架，将范式从静态模型选择转变为动态、预算感知的顺序决策。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [14] [ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following](https://arxiv.org/abs/2602.21228)
*Yuancheng Yang,Lin Yang,Xu Wang,Chao Tong,Haihua Yang*

Main category: cs.CL

TL;DR: ImpRIF方法通过将隐式推理指令形式化为可验证的推理图，增强大语言模型对复杂指令的理解和遵循能力，在五个基准测试中显著超越基础模型。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日益复杂，对鲁棒的复杂指令遵循能力需求增长。作者认为深入理解指令本身，特别是隐藏在字里行间的潜在推理结构，对提升指令遵循能力至关重要。因此针对涉及隐式推理、复杂逻辑关系和多约束依赖的复杂指令进行研究。

Method: 提出ImpRIF方法，将隐式推理指令形式化为可验证的推理图，支持程序化验证和图驱动的思维链推理。基于此形式化，合成大规模单轮和多轮数据，提出基于图推理的微调，并应用强化学习明确训练模型沿图进行推理。

Result: 在五个复杂指令遵循基准测试中，ImpRIF模型显著优于其基础模型。结果表明增强隐式推理能力可以显著改善复杂指令遵循性能。

Conclusion: 通过将隐式推理指令形式化为可验证推理图，ImpRIF方法有效增强了大语言模型对复杂指令的理解和遵循能力，为解决复杂指令遵循问题提供了新思路。该项目将在近期开源。

Abstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.

</details>


### [15] [TRACE: Trajectory-Aware Comprehensive Evaluation for Deep Research Agents](https://arxiv.org/abs/2602.21230)
*Yanyu Chen,Jiyue Jiang,Jiahong Liu,Yifei Zhang,Xiao Guo,Irwin King*

Main category: cs.CL

TL;DR: TRACE框架通过轨迹感知的综合评估解决深度研究智能体评估中的"高分幻觉"和静态基准局限性问题


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体评估存在两个主要问题：1) 过度依赖Pass@1等单一指标，造成"高分幻觉"，忽略了推理过程的质量、效率和合理性；2) 静态基准无法量化鲁棒性和潜在能力等关键属性

Method: 提出TRACE框架，包含分层轨迹效用函数量化过程效率和认知质量，以及支架式能力评估协议通过最小指导需求来量化智能体的潜在能力

Result: TRACE能够提供细粒度排名，揭示智能体在准确性、效率和鲁棒性之间的关键权衡，这些权衡被单一指标完全忽略

Conclusion: TRACE框架为深度研究智能体提供了更全面、更细粒度的评估方法，克服了传统评估的局限性，有助于更准确地理解和比较智能体的真实能力

Abstract: The evaluation of Deep Research Agents is a critical challenge, as conventional outcome-based metrics fail to capture the nuances of their complex reasoning. Current evaluation faces two primary challenges: 1) a reliance on singular metrics like Pass@1, creating a "high-score illusion" that ignores the quality, efficiency, and soundness of the reasoning process; and 2) the failure of static benchmarks to quantify crucial attributes like robustness and latent capability. To address these gaps, we introduce TRACE (Trajectory-Aware Comprehensive Evaluation), a framework that holistically assesses the entire problem-solving trajectory. To counter the "high-score illusion", we propose a Hierarchical Trajectory Utility Function that quantifies process efficiency and cognitive quality, including evidence grounding, alongside accuracy. To measure deeper attributes, TRACE introduces a Scaffolded Capability Assessment protocol, quantifying an agent's latent ability by determining the minimum guidance needed for success. Our contributions include the TRACE framework, its novel metrics, and the accompanying DeepResearch-Bench with controllable complexity. Experiments show TRACE delivers a granular ranking that uncovers critical trade-offs between agent accuracy, efficiency, and robustness entirely missed by singular metrics.

</details>


### [16] [Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment](https://arxiv.org/abs/2602.21346)
*Mengxuan Hu,Vivek V. Datla,Anoop Kumar,Zihan Guan,Sheng Li,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 该论文提出通过推理感知的后训练增强LLM对齐鲁棒性，包括构建CoT微调数据集和引入Alignment-Weighted DPO方法，以解决现有对齐技术对越狱攻击的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 尽管SFT、RLHF和DPO等对齐技术提升了LLM的安全性，但模型仍容易受到通过间接或欺骗性措辞伪装的越狱攻击。作者通过因果干预实证表明，这种脆弱性源于缺乏深度推理的浅层对齐机制，模型往往在不真正理解有害性的情况下拒绝有害提示。

Method: 1. 构建并发布新颖的CoT微调数据集，包含实用导向和安全关键提示及其逐步推理过程；2. 提出Alignment-Weighted DPO方法，通过对推理段和最终答案段分配不同偏好权重，针对输出中最有问题的部分进行更细粒度的目标更新。

Result: 在多个安全和实用基准测试上的广泛实验表明，该方法在保持模型整体实用性的同时，一致地提高了对齐鲁棒性。CoT微调使模型能够产生基于推理的原则性拒绝，优于标准SFT基线。Alignment-Weighted DPO相比普通DPO产生更细粒度的目标更新，并提高了对多样化越狱策略的鲁棒性。

Conclusion: 通过推理感知的后训练增强对齐，特别是结合CoT微调和Alignment-Weighted DPO，能够有效提高LLM对越狱攻击的鲁棒性，同时保持模型实用性，为解决浅层对齐机制的局限性提供了有效途径。

Abstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.

</details>


### [17] [Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages](https://arxiv.org/abs/2602.21374)
*Mohammadreza Ghaffarzadeh-Esfahani,Nahid Yousefian,Ebrahim Heidari-Farsani,Ali Akbar Omidvarian,Sepehr Ghahraei,Atena Farangi,AmirBahador Boroumand*

Main category: cs.CL

TL;DR: 评估开源小语言模型在波斯语医疗转录本中提取临床特征的性能，采用两步流程：先翻译后提取，发现较大模型（7B-8B参数）表现更好，翻译能提升敏感度但略微降低特异性


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（波斯语）医疗转录本中临床信息提取的挑战，为资源有限的多语言临床NLP环境提供实用、隐私保护的解决方案

Method: 采用两步流程：1) 使用Aya-expanse-8B将波斯语转录本翻译为英语；2) 使用五种开源小语言模型（Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, Gemma-3-1B-it）进行13个临床特征的二元提取，采用少量样本提示策略而不进行微调

Result: Qwen2.5-7B-Instruct表现最佳（中位数宏F1: 0.899; MCC: 0.797），较大模型（7B-8B参数）在敏感度和MCC上持续优于较小模型。翻译波斯语到英语能提升敏感度、减少缺失输出、增强对类别不平衡鲁棒的指标，但略微降低特异性和精确度。生理症状提取可靠，而心理抱怨、行政请求和复杂躯体特征仍具挑战性

Conclusion: 为资源有限的多语言临床NLP环境提供了实用的隐私保护蓝图，强调了在敏感医疗应用中联合优化模型规模和输入语言策略的重要性

Abstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.

</details>


### [18] [Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages](https://arxiv.org/abs/2602.21377)
*Felix Schneider,Maria Gogolev,Sven Sickert,Joachim Denzler*

Main category: cs.CL

TL;DR: 提出Rich Character Embeddings (RCE)方法，直接从字符序列计算词向量，结合语义和句法信息，并引入transformer与卷积的混合模型，作为现有模型中字典和子词嵌入的替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统基于token和sub-token的模型（如word2vec、BERT、GPT）在输入表示上存在局限，无法充分捕捉正字法相似性和形态变化，特别是在高度屈折和资源匮乏的语言中。

Method: 提出Rich Character Embeddings (RCE)方法，基于transformer直接从字符序列计算词向量，集成语义和句法信息；同时提出transformer与卷积机制结合的混合模型。这些向量表示可作为现有模型架构中字典和子词嵌入的直接替代。

Result: 在SWAG、屈折语言的变格预测、多种语言的隐喻和交错法检测等任务上评估，实验表明在有限数据下使用OddOneOut和TopK指标时，该方法优于传统的基于token的方法。

Conclusion: RCE方法有潜力改善大型上下文语言模型（如BERT）和小型模型（如word2vec）在资源匮乏和形态丰富语言上的性能，提供更全面的词表示方法。

Abstract: Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.

</details>


### [19] [MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation](https://arxiv.org/abs/2602.21379)
*Daniel Tamayo,Iñaki Lacunza,Paula Rivera-Hidalgo,Severino Da Dalt,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: MrBERT是基于ModernBERT架构的150M-300M参数编码器，支持35种语言和代码，在加泰罗尼亚语和西班牙语任务上达到SOTA，在生物医学和法律领域表现优异，并采用MRL实现灵活向量尺寸以降低推理和存储成本。


<details>
  <summary>Details</summary>
Motivation: 解决现代编码器架构在特定语言任务和领域专业化方面的优化问题，同时降低生产环境中的推理和存储成本。

Method: 基于ModernBERT架构构建150M-300M参数编码器，在35种语言和代码上进行预训练，通过针对性适应优化特定语言任务，并集成Matryoshka表示学习实现灵活向量尺寸。

Result: 在加泰罗尼亚语和西班牙语特定任务上达到最先进水平，在生物医学和法律专业领域建立稳健性能，通过MRL显著降低推理和存储成本。

Conclusion: 现代编码器架构可以同时优化本地语言卓越性和高效的高风险领域专业化，MrBERT家族已在Huggingface开源。

Abstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.

</details>


### [20] [VecGlypher: Unified Vector Glyph Generation with Language Models](https://arxiv.org/abs/2602.21461)
*Xiaoke Huang,Bhavul Gauri,Kam Woh Ng,Tony Ng,Mengmeng Xu,Zhiheng Liu,Weiming Ren,Zhaochong An,Zijian Zhou,Haonan Qiu,Yuyin Zhou,Sen He,Ziheng Wang,Tao Xiang,Xiao Han*

Main category: cs.CL

TL;DR: VecGlypher是一个多模态语言模型，能够直接从文本描述或图像示例生成高质量矢量字形，无需光栅中间处理，产生可编辑的SVG路径。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的字体生成管道依赖精心策划的示例表和光栅到矢量后处理，限制了可访问性和可编辑性。需要一种能够直接生成矢量字形的解决方案。

Method: 采用两阶段训练方法：1) 在39K个嘈杂Envato字体上进行大规模预训练以掌握SVG语法和长序列几何；2) 在2.5K个专家标注的Google字体上进行后训练，对齐语言、图像与几何。预处理包括坐标框架归一化、路径规范化、去重和坐标量化。

Result: 在跨家族OOD评估中，VecGlypher在纯文本生成方面显著优于通用LLM和专用矢量字体基线，图像参考生成达到最先进性能，明显优于DeepVecFont-v2和DualVector。消融研究表明模型规模和两阶段训练方案是关键因素。

Conclusion: VecGlypher通过让用户用文字或示例设计字体，降低了字体创建门槛，为未来多模态设计工具提供了可扩展的基础。

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

</details>


### [21] [Evaluating the Usage of African-American Vernacular English in Large Language Models](https://arxiv.org/abs/2602.21485)
*Deja Dunlap,R. Thomas McCoy*

Main category: cs.CL

TL;DR: LLMs在表示非裔美国人白话英语（AAVE）方面存在显著偏差，与母语使用者的实际使用模式不符，且会复制对非裔美国人的刻板印象。


<details>
  <summary>Details</summary>
Motivation: 当前AI对自然语言理解任务的评估主要基于标准方言（如标准美式英语），缺乏对非标准方言如AAVE的准确表示研究，这可能导致模型对特定语言社区的偏见和刻板印象。

Method: 使用区域非裔美国人语言语料库和TwitterAAE分析人类AAVE使用模式，特别是语法特征如"ain't"；然后提示三个LLM生成AAVE文本，将模型生成文本与人类使用模式进行比较；通过情感分析和人工检查评估模型输出。

Result: LLMs与人类AAVE使用存在显著差异：模型通常对AAVE特征性语法元素使用不足且误用；通过情感分析和人工检查发现模型复制了对非裔美国人的刻板印象。

Conclusion: 研究结果强调需要更多样化的训练数据和采用公平性方法来减轻刻板印象的延续，确保AI系统对所有语言变体都能准确、公平地表示。

Abstract: In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.

</details>


### [22] [Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment](https://arxiv.org/abs/2602.21543)
*Barah Fazili,Koustava Goswami*

Main category: cs.CL

TL;DR: 通过多语言并行语料库进行对比学习训练，显著提升多语言预训练模型的跨语言对齐能力，在多个NLU任务上取得性能提升


<details>
  <summary>Details</summary>
Motivation: 传统的多语言预训练缺乏显式的对齐信号，导致表示空间中的跨语言对齐不理想。需要探索如何通过多语言并行数据改善跨语言表示对齐。

Method: 构建多语言并行数据集：使用现成的NMT模型将英语文本翻译成6种目标语言。通过对比学习在多语言并行语料库上训练标准预训练模型（XLM-Roberta和mBERT），实现跨语言对齐。

Result: 相比英语中心的双语并行数据，多语言并行对比训练在多个任务上取得显著提升：双语文本挖掘（21.3%）、语义相似度（5.3%）、分类任务（28.4%）。即使在已预训练的高质量句子嵌入模型（mE5）上进行微调，多语言并行数据也能显著改善双语文本挖掘性能。

Conclusion: 使用多语言并行语料库进行对比学习训练能有效改善跨语言表示对齐，提升多语言和跨语言NLU任务性能。多语言跨语言监督对即使是已预训练的高质量句子嵌入模型也至关重要。

Abstract: Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.

</details>


### [23] [MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification](https://arxiv.org/abs/2602.21608)
*Kazi Samin Yasar Alam,Md Tanbir Chowdhury,Tamim Ahmed,Ajwad Abrar,Md Rafid Haque*

Main category: cs.CL

TL;DR: 首个公开的孟加拉语-英语代码混合语料库MixSarc，包含9,087个标注句子，用于幽默、讽刺、冒犯和粗俗的隐式含义识别，填补了南亚社交媒体代码混合NLP的资源空白。


<details>
  <summary>Details</summary>
Motivation: 现有情感和讽刺检测模型主要针对单语英语或高资源语言，难以处理孟加拉语-英语代码混合中的音译变异、文化引用和句内语言切换问题，缺乏相关资源支持。

Method: 通过定向社交媒体收集、系统过滤和多标注者验证构建语料库；使用基于Transformer的模型进行基准测试，并在结构化提示下评估零样本大语言模型。

Result: 幽默检测表现良好，但讽刺、冒犯和粗俗检测因类别不平衡和语用复杂性而显著下降；零样本模型获得有竞争力的微平均F1分数但精确匹配准确率低；外部数据集中超过42%的负面情感实例具有讽刺特征。

Conclusion: MixSarc为文化感知NLP提供了基础资源，支持代码混合环境中更可靠的多标签建模，揭示了代码混合隐式含义识别的挑战和机遇。

Abstract: Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.

</details>


### [24] [When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning](https://arxiv.org/abs/2602.21619)
*Muku Akasaka,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 视觉空间推理中信息注入的假设驱动分析：更多信息不一定更好，需要选择性、任务对齐的信息注入


<details>
  <summary>Details</summary>
Motivation: 尽管多模态架构有所进展，但视觉空间推理（VSR）对现代视觉语言模型（VLMs）仍然具有挑战性。常见的策略是在推理时注入额外信息（如显式空间线索、外部常识知识或思维链推理指令），但尚不清楚这些信息何时真正改善推理，何时引入噪声。

Method: 对三个代表性VLMs和两个公共基准进行假设驱动的信息注入分析，考察：(i) 空间上下文的类型和数量，(ii) 注入常识知识的数量和相关性，(iii) 空间基础与思维链提示之间的相互作用。

Result: 揭示了一致模式：更多信息不一定产生更好的推理。有针对性的单一空间线索优于多上下文聚合，过多或弱相关的常识知识会降低性能，思维链提示只有在空间基础足够精确时才能提高准确性。

Conclusion: 强调了选择性、任务对齐的信息注入的重要性，为设计可靠的多模态推理流程提供了实用指导。

Abstract: Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.

</details>


### [25] [RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2602.21628)
*Yukun Chen,Jiaming Li,Longze Chen,Ze Gong,Jingpeng Li,Zhen Qin,Hengyu Chang,Ancheng Xu,Zhihao Yang,Hamid Alinejad-Rokny,Qiang Qu,Bo Zheng,Min Yang*

Main category: cs.CL

TL;DR: RuCL是一种分层课程学习框架，通过动态调整评分标准权重，引导多模态大语言模型从基础感知逐步学习到高级逻辑推理，有效避免奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于可验证奖励的强化学习范式存在奖励黑客风险，模型可能学习虚假推理模式来满足最终答案检查。现有的基于评分标准的方法虽然提供细粒度监督信号，但存在实例级生成计算成本高、将所有评分标准视为同等可学习导致训练效率低下的问题。

Method: 提出分层评分标准课程学习框架RuCL，将课程学习的重点从数据选择转向奖励设计。方法包括：1）生成具有广泛适用性的通用评分标准；2）根据模型能力对评分标准进行分层；3）在训练过程中动态调整评分标准权重，引导模型从掌握基础感知逐步过渡到处理高级逻辑推理。

Result: 在各种视觉推理基准测试中，RuCL相比Qwen2.5-VL-7B模型平均提升了7.83%，达到了60.06%的最先进准确率。

Conclusion: RuCL通过将课程学习重新定义为奖励设计问题，有效解决了现有评分标准方法的局限性，在避免奖励黑客的同时显著提升了多模态大语言模型的推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.

</details>


### [26] [Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs](https://arxiv.org/abs/2602.21638)
*Anqi Li,Ruihan Wang,Zhaoming Chen,Yuqian Chen,Yu Lu,Yi Zhu,Yuan Xie,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 开发了一个AI系统，用于评估心理咨询师应对客户抵抗的干预质量，通过理论驱动的框架分解咨询师回应为四种沟通机制，并生成解释性反馈，显著提升咨询师应对能力。


<details>
  <summary>Details</summary>
Motivation: 心理咨询中有效应对客户抵抗是一项复杂的临床技能，但从业者往往缺乏及时、可扩展的监督反馈来改进方法。现有NLP研究主要关注整体咨询质量和一般治疗技能，无法对客户表现出抵抗的高风险时刻提供细粒度评估。

Method: 提出了一个理论驱动框架，将咨询师回应分解为四种不同的沟通机制。收集并分享了专家标注的真实咨询对话数据集，包含咨询师-客户互动、专业评分和解释性理由。使用该数据对Llama-3.1-8B-Instruct骨干模型进行全参数指令调优，以建模细粒度的回应质量评估并生成底层解释。

Result: 该方法能有效区分不同沟通机制的质量（77-81% F1），显著优于GPT-4o和Claude-3.5-Sonnet（45-59% F1）。模型生成的高质量解释与专家参考高度一致，获得接近上限的人类专家评分（2.8-2.9/3.0）。43名咨询师的对照实验证实，接收这些AI生成的反馈能显著提升咨询师有效应对客户抵抗的能力。

Conclusion: 该研究开发了一个全面的多维度评估管道，专门针对文本治疗中的客户抵抗，为心理咨询师提供了可扩展的监督反馈系统，显著改善了临床实践中应对客户抵抗的技能发展。

Abstract: Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.

</details>


### [27] [Mitigating Structural Noise in Low-Resource S2TT: An Optimized Cascaded Nepali-English Pipeline with Punctuation Restoration](https://arxiv.org/abs/2602.21647)
*Tangsang Chongbang,Pranesh Pyara Shrestha,Amrit Sarki,Anku Jaiswal*

Main category: cs.CL

TL;DR: 该论文提出并评估了一个优化的级联尼泊尔语语音到英语文本翻译系统，通过标点恢复模块缓解ASR引入的结构噪声，显著提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）输出的无标点文本会引入结构噪声，显著降低机器翻译质量（在FLORES基准上导致20.7%的相对BLEU下降），需要针对性解决方案。

Method: 首先建立高性能ASR（Wav2Vec2-XLS-R-300m）和NMT（多阶段微调MarianMT）组件，然后提出并评估中间标点恢复模块（PRM），在三种配置下测试最终S2TT流水线。

Result: 最优配置（PRM直接应用于ASR输出）相比直接ASR-to-NMT基线获得4.90 BLEU点提升（36.38 vs. 31.48），人类评估确认了优化流水线在充分性（3.673）和流畅性（3.804）方面的优越性。

Conclusion: 针对性标点恢复是缓解尼泊尔语S2TT流水线中结构噪声的最有效干预措施，为类似低资源语言开发级联语音翻译系统提供了关键架构洞察和优化基线。

Abstract: This paper presents and evaluates an optimized cascaded Nepali speech-to-English text translation (S2TT) system, focusing on mitigating structural noise introduced by Automatic Speech Recognition (ASR). We first establish highly proficient ASR and NMT components: a Wav2Vec2-XLS-R-300m model achieved a state-of-the-art 2.72% CER on OpenSLR-54, and a multi-stage fine-tuned MarianMT model reached a 28.32 BLEU score on the FLORES-200 benchmark. We empirically investigate the influence of punctuation loss, demonstrating that unpunctuated ASR output significantly degrades translation quality, causing a massive 20.7% relative BLEU drop on the FLORES benchmark. To overcome this, we propose and evaluate an intermediate Punctuation Restoration Module (PRM). The final S2TT pipeline was tested across three configurations on a custom dataset. The optimal configuration, which applied the PRM directly to ASR output, achieved a 4.90 BLEU point gain over the direct ASR-to-NMT baseline (BLEU 36.38 vs. 31.48). This improvement was validated by human assessment, which confirmed the optimized pipeline's superior Adequacy (3.673) and Fluency (3.804). This work validates that targeted punctuation restoration is the most effective intervention for mitigating structural noise in the Nepali S2TT pipeline. It establishes an optimized baseline and demonstrates a critical architectural insight for developing cascaded speech translation systems for similar low-resource languages.

</details>


### [28] [Sparsity Induction for Accurate Post-Training Pruning of Large Language Models](https://arxiv.org/abs/2602.21652)
*Minhao Jiang,Zhikai Li,Xuewen Liu,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CL

TL;DR: 提出Sparsity Induction方法，通过在剪枝前从分布和特征两个层面提升模型稀疏性，突破后训练稀疏化的极限


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模增长带来计算和内存效率挑战，后训练稀疏化是有效方法，但原生稠密矩阵缺乏高稀疏性，直接剪枝会破坏模型状态，即使后调优也难以恢复满意性能

Method: 提出Sparsity Induction方法：1) 分布层面：通过数学等价缩放变换增强分布稀疏性，完全可吸收且无额外参数或推理开销；2) 特征层面：引入谱范数损失从低秩角度促进特征稀疏性

Result: 在不同模型架构和任务上的实验表明，该方法进一步增强了稀疏友好性，在剪枝性能上优于现有方法

Conclusion: Sparsity Induction通过在剪枝前从分布和特征层面提升模型稀疏性，有效突破了后训练稀疏化的性能极限

Abstract: Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.

</details>


### [29] [DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation](https://arxiv.org/abs/2602.21669)
*Duc Trung Vu,Pham Khanh Chi,Dat Phi Van,Linh Ngo Van,Sang Dinh,Trung Le*

Main category: cs.CL

TL;DR: DWA-KD是一种新颖的跨分词器知识蒸馏框架，通过双空间熵加权和时间扭曲对齐，在token级和序列级同时优化教师-学生模型的知识传递，显著提升跨分词器知识蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨分词器知识蒸馏方法在序列级和词汇级对齐方面存在局限性，导致知识传递效果受限。需要一种能够同时优化token级和序列级对齐的蒸馏框架。

Method: 提出DWA-KD框架：1) token级：通过双向映射和KL散度进行双空间知识蒸馏，使用基于熵的双空间权重对不确定学生token和确定教师token进行加权；2) 序列级：在嵌入层和最终隐藏状态层应用Soft动态时间扭曲对齐，实现词汇和上下文语义的鲁棒对齐。

Result: 在多种NLP基准测试中，DWA-KD优于现有最先进的知识蒸馏基线方法。消融研究证实了熵基token加权与嵌入层/最终隐藏状态层Soft-DTW对齐的互补贡献。

Conclusion: DWA-KD通过双空间加权和时间扭曲对齐有效解决了跨分词器知识蒸馏中的对齐问题，为大型语言模型压缩提供了更有效的解决方案。

Abstract: Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.

</details>


### [30] [Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning](https://arxiv.org/abs/2602.21720)
*Andrea Silvi,Ponrawee Prasertsom,Jennifer Culbertson,Devdatt Dubhashi,Moa Johansson,Kenny Smith*

Main category: cs.CL

TL;DR: 研究发现人类递归数字系统的规律性促进学习，解释了为何规律系统在跨语言中更普遍，而不同系统类型受不同学习压力影响。


<details>
  <summary>Details</summary>
Motivation: 探究人类递归数字系统（如英语十进制数字）为何普遍具有高度规律性，检验"规律性促进学习"这一假设是否解释了跨语言趋势。

Method: 采用强化学习方法，比较规律系统与不规则系统的学习难度，基于"递归数字系统旨在从有限数据泛化以精确表示所有整数"的自然假设。

Result: 高度规律的人类（类人）系统比未出现但可能的不规则系统更容易学习；对于不自然的高度不规则系统，规律性影响消失，学习性受信号长度影响。

Conclusion: 规律性促进学习解释了人类数字系统的跨语言普遍性，不同系统类型受不同学习压力影响，支持了可学习性与语言普遍性之间的联系。

Abstract: Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.

</details>


### [31] [Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling](https://arxiv.org/abs/2602.21728)
*Shiqi Yan,Yubo Chen,Ruiqi Zhou,Zhengxi Yao,Shuai Chen,Tianyi Zhang,Shijie Zhang,Wei Qiang Zhang,Yongfeng Huang,Haixin Duan,Yunqi Zhang*

Main category: cs.CL

TL;DR: EoG框架通过强化学习激励LLM在知识图谱上自主探索多样化推理路径，解决传统KG增强方法泛化性不足的问题，在多个KGQA基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱增强的方法通常通过生成规则约束或固定演示路径来限制LLM推理，这导致推理模式局限于先验经验或微调数据范围，限制了在分布外图推理问题上的泛化能力。

Method: 提出Explore-on-Graph框架，通过强化学习训练激励LLM在KG上自主探索多样化推理路径，奖励基于推理路径最终答案的正确性，并引入路径信息作为额外奖励信号来优化探索过程、减少无效探索。

Result: 在五个KGQA基准数据集上的广泛实验表明，该方法达到了最先进的性能，不仅超越了开源LLM，甚至超越了闭源LLM。

Conclusion: EoG框架通过强化学习驱动的自主探索机制，有效提升了LLM在知识图谱上的推理能力和泛化性，为解决LLM在问答任务中的幻觉和事实缺失问题提供了新思路。

Abstract: The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.

</details>


### [32] [Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization](https://arxiv.org/abs/2602.21741)
*MD. Sagor Chowdhury,Adiba Fairooz Chowdhury*

Main category: cs.CL

TL;DR: 该论文介绍了参加Kaggle DL Sprint 4.0竞赛的孟加拉语长语音识别和说话人日志系统，通过语音分离、静音边界分块和领域特定微调等技术，在低资源孟加拉语场景下取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语语音处理面临重大挑战：音素库大、方言变异显著、与英语频繁混用、大规模标注语料相对稀缺。需要开发专门针对这些挑战的端到端系统。

Method: 1. ASR部分：结合BengaliAI微调的Whisper medium模型、Demucs声源分离进行人声隔离、静音边界分块和精心调优的生成超参数。2. 说话人日志部分：将pyannote.audio流水线中的默认分割模型替换为孟加拉语微调变体，配合wespeaker-voxceleb-resnet34-LM嵌入和基于质心的凝聚聚类。

Result: ASR最佳私有WER为0.37738，公开WER为0.36137；说话人日志最佳私有DER为0.27671，公开DER为0.20936。实验表明分割组件领域特定微调、声源分离和自然静音感知分块是影响最大的设计选择。

Conclusion: 在低资源孟加拉语语音处理中，分割模型的领域特定微调、声源分离和自然静音感知分块是三个最关键的设计决策，能显著提升ASR和说话人日志性能。

Abstract: We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whisper medium model with Demucs source separation for vocal isolation, silence-boundary chunking, and carefully tuned generation hyperparameters. For speaker diarization we reach a best private Diarization Error Rate (DER) of 0.27671 and public DER of 0.20936 by replacing the default segmentation model inside the pyannote.audio pipeline with a Bengali-fine-tuned variant, pairing it with wespeaker-voxceleb-resnet34-LM embeddings and centroid-based agglomerative clustering. Our experiments demonstrate that domain-specific fine-tuning of the segmentation component, vocal source separation, and natural silence-aware chunking are the three most impactful design choices for low-resource Bengali speech processing.

</details>


### [33] [Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs](https://arxiv.org/abs/2602.21763)
*Heng Wang,Changxing Wu*

Main category: cs.CL

TL;DR: 利用大语言模型的推理能力蒸馏到轻量级隐式篇章关系识别模型中，提升性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系识别需要深度语义理解且缺乏显式标记，现有方法仅预测关系而不提供解释支持。大语言模型在深度语言理解和自然语言解释生成方面展现出强大推理能力。

Method: 首先提示大语言模型基于黄金标签为每个训练实例生成解释，然后引入新颖的分类-生成框架联合执行关系预测和解释生成，并使用大语言模型生成的解释作为额外监督进行训练。

Result: 在PDTB数据集上的实验结果表明，该方法显著提升了隐式篇章关系识别性能，人工评估进一步证实生成的解释增强了模型可解释性。该方法在情感分类和自然语言推理任务上也验证了泛化性。

Conclusion: 通过将大语言模型的推理能力蒸馏到轻量级模型中，提出了一种简单有效的提升隐式篇章关系识别性能和可解释性的方法，该方法具有即插即用特性，可轻松集成到现有模型中。

Abstract: Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting explanations. Recent advances in large language models (LLMs) have shown strong reasoning capabilities in both deep language understanding and natural language explanation generation. In this work, we propose a simple yet effective approach to distill the reasoning capabilities of LLMs into lightweight IDRR models to improve both performance and interpretability. Specifically, we first prompt an LLM to generate explanations for each training instance conditioned on its gold label. Then, we introduce a novel classification-generation framework that jointly performs relation prediction and explanation generation, and train it with the additional supervision of LLM-generated explanations. Our framework is plug-and-play, enabling easy integration with most existing IDRR models. Experimental results on PDTB demonstrate that our approach significantly improves IDRR performance, while human evaluation further confirms that the generated explanations enhance model interpretability. Furthermore, we validate the generality of our approach on sentiment classification and natural language inference

</details>


### [34] [D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models](https://arxiv.org/abs/2602.21786)
*Shunsuke Ubukata*

Main category: cs.CL

TL;DR: 提出D-CoT框架，通过控制标签结构化推理过程，解决小语言模型在CoT蒸馏中的"过度思考"问题，同时提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统CoT蒸馏方法在大语言模型到小语言模型的知识迁移中，容易导致小模型出现"过度思考"现象，表现为性能下降和计算资源浪费。需要一种能规范推理过程、抑制推理漂移的方法。

Method: 提出Disciplined Chain-of-Thought (D-CoT)框架，使用控制标签（如<TEMP_LOW>用于事实核查，<TEMP_HIGH>用于多视角探索）作为训练时的辅助支架，优化CoT轨迹，抑制推理漂移。

Result: 在Qwen3-8B模型上，仅用5,000训练样本，D-CoT使GPQA-diamond准确率提升9.9%，MMLU-Pro (0-shot)提升9.1%，同时大幅降低计算成本。模型内化了这种结构化思维，推理时无需显式控制标签仍保持高性能。

Conclusion: D-CoT框架通过结构化推理过程有效解决了小语言模型的"过度思考"问题，实现了性能提升与计算效率的双重优化，为高效的知识蒸馏提供了新思路。

Abstract: Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.

</details>


### [35] [FewMMBench: A Benchmark for Multimodal Few-Shot Learning](https://arxiv.org/abs/2602.21854)
*Mustafa Dogan,Ilker Kesen,Iacer Calixto,Aykut Erdem,Erkut Erdem*

Main category: cs.CL

TL;DR: FewMMBench是一个评估多模态大语言模型少样本学习能力的基准，涵盖多种任务类型，评估了26个模型在零样本、少样本和思维链增强设置下的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在处理交错图像-文本数据方面的进步，评估其少样本学习能力仍然是一个未解决的挑战。需要建立一个全面的基准来系统评估MLLMs在少样本条件下的表现。

Method: 提出了FewMMBench基准，涵盖从属性识别到时序推理的多样化多模态理解任务。评估了来自6个模型家族的26个开源MLLMs，在零样本、少样本和思维链增强的少样本设置下进行系统分析。

Result: 指令调优模型在零样本设置下表现强劲，但通过额外演示或思维链推理获得的收益有限甚至出现性能下降。基于检索的演示和增加上下文大小也只能带来有限的提升。

Conclusion: FewMMBench为诊断和推进多模态大语言模型的少样本能力提供了一个严格的测试平台。研究结果表明当前MLLMs在少样本学习方面仍有改进空间。

Abstract: As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench

</details>


### [36] [Personalized Graph-Empowered Large Language Model for Proactive Information Access](https://arxiv.org/abs/2602.21862)
*Chia Cheng Chang,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 提出一个基于大语言模型和个人知识图谱的框架，用于主动帮助用户回忆被遗忘的生活经历，解决传统深度学习方法需要大量训练数据和难以适应新增生活日志的问题。


<details>
  <summary>Details</summary>
Motivation: 个人难以完整回忆生活细节且容易混淆事件，需要系统辅助回忆。现有记忆回忆系统主要依赖深度学习技术，需要大量训练数据且面临个人生活日志数据稀缺的问题。随着生活日志随时间增长，系统需要快速适应新增数据。大语言模型在各种任务中表现出色，为个性化应用提供了新可能。

Method: 提出一个利用大语言模型进行主动信息访问的框架，整合个人知识图谱，通过改进的决策过程增强访问需求检测。框架具有高度灵活性，允许替换基础模型和修改事实检索方法以实现持续改进。

Result: 实验结果表明，该方法能有效识别被遗忘的事件，支持用户更高效地回忆过去经历。

Conclusion: 基于大语言模型和个人知识图谱的框架为解决个人记忆回忆问题提供了有效方案，具有灵活性和适应性优势。

Abstract: Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.

</details>


### [37] [ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection](https://arxiv.org/abs/2602.21887)
*Changjiang Gao,Zixian Huang,Kaichen Yang,Jiajun Chen,Jixing Li,Shujian Huang*

Main category: cs.CL

TL;DR: ExpLang：一种新颖的LLM后训练流程，通过多语言思维选择来增强强化学习中的探索和利用，相比纯英语训练在相同预算下表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型主要专注于英语推理以获得最佳性能，但忽视了多语言思维的潜在优势以及全球用户对母语思维轨迹的需求。

Method: 提出ExpLang，一种LLM后训练流程，通过在强化学习中启用策略内思维语言选择作为动作，利用多语言扩展RL探索空间并提升利用效果。

Result: 在相同训练预算下，ExpLang稳定优于纯英语训练，对已见和未见语言都显示出高思维语言遵从性。分析表明多语言选择有效扩展了RL探索空间并利用了非英语优势。

Conclusion: 该方法与大多数RL算法正交，为利用多语言性改进大型推理模型开辟了新视角。

Abstract: Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.

</details>


### [38] [Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models](https://arxiv.org/abs/2602.22072)
*Christian Nickel,Laura Schrewe,Florian Mai,Lucie Flek*

Main category: cs.CL

TL;DR: LLM在错误信念任务中的心理理论能力在扰动下急剧下降，质疑其稳健性；思维链提示能提升整体性能但可能在某些扰动类型中降低准确性


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否具备真正的心理理论能力，通过扰动测试其稳健性，并研究思维链提示是否能增强性能并解释模型决策

Method: 创建手工标注的心理理论数据集，包含经典和扰动的错误信念任务、有效推理链空间、推理忠实度、任务解决方案；提出评估推理链正确性和答案对推理轨迹忠实度的指标；测试不同LLM在扰动下的表现

Result: 所有评估的LLM在任务扰动下心理理论能力急剧下降，质疑任何稳健心理理论形式的存在；思维链提示总体上能忠实提升心理理论性能，但令人惊讶的是在某些扰动类型中会降低准确性

Conclusion: LLM的心理理论能力缺乏稳健性，思维链提示需要选择性应用；研究为评估LLM心理理论能力提供了新方法和数据集

Abstract: Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.

</details>


### [39] [Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text](https://arxiv.org/abs/2602.21933)
*Bitan Majumder,Anirban Sen*

Main category: cs.CL

TL;DR: 在低资源代码混合文本中，经过微调的DistilBERT模型在讽刺检测任务上优于多个大型语言模型，达到84%准确率


<details>
  <summary>Details</summary>
Motivation: 多语言和代码混合环境中的讽刺检测对NLP模型具有挑战性，因为存在结构变化、非正式表达和低资源语言可用性问题

Method: 比较了四个大型语言模型（Llama 3.1、Mistral、Gemma 3、Phi-4）与经过微调的DistilBERT模型在代码混合Hinglish文本中的讽刺检测性能，使用少量LLM生成的代码混合数据进行微调

Result: 经过顺序微调的DistilBERT模型达到84%的整体准确率，在零样本和少样本设置中均优于所有大型语言模型

Conclusion: 在低资源和数据稀缺环境下，对小型Transformer模型进行领域自适应微调可能比通用LLM推理在讽刺检测任务上表现更好

Abstract: Sarcasm detection in multilingual and code-mixed environments remains a challenging task for natural language processing models due to structural variations, informal expressions, and low-resource linguistic availability. This study compares four large language models, Llama 3.1, Mistral, Gemma 3, and Phi-4, with a fine-tuned DistilBERT model for sarcasm detection in code-mixed Hinglish text. The results indicate that the smaller, sequentially fine-tuned DistilBERT model achieved the highest overall accuracy of 84%, outperforming all of the LLMs in zero and few-shot set ups, using minimal LLM generated code-mixed data used for fine-tuning. These findings indicate that domain-adaptive fine-tuning of smaller transformer based models may significantly improve sarcasm detection over general LLM inference, in low-resource and data scarce settings.

</details>


### [40] [Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets](https://arxiv.org/abs/2602.22207)
*Hanna Yukhymenko,Anton Alexandrov,Martin Vechev*

Main category: cs.CL

TL;DR: 提出自动化框架解决多语言LLM评估中翻译基准质量不一致问题，通过USI和T-RANK方法提升翻译质量，在8种东欧和南欧语言上验证效果优于现有资源。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大语言模型评估的可靠性受到翻译基准质量不一致的损害。现有资源常存在语义漂移和上下文丢失问题，导致误导性的性能指标。

Method: 提出全自动化框架，采用测试时计算缩放策略，特别是通用自我改进（USI）和提出的多轮排序方法T-RANK，相比传统流水线能显著提高翻译质量。框架确保基准在本地化过程中保留原始任务结构和语言细微差别。

Result: 将方法应用于8种东欧和南欧语言（乌克兰语、保加利亚语、斯洛伐克语、罗马尼亚语、立陶宛语、爱沙尼亚语、土耳其语、希腊语）的流行基准和数据集翻译。使用基于参考的指标和LLM-as-a-judge评估显示，翻译质量超越现有资源，实现更准确的下游模型评估。

Conclusion: 发布框架和改进的基准，以促进稳健且可复现的多语言AI开发。该工作解决了多语言评估中的关键翻译质量问题，为更可靠的跨语言模型比较提供了解决方案。

Abstract: The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.

</details>


### [41] [Large Language Models are Algorithmically Blind](https://arxiv.org/abs/2602.21947)
*Sohan Venkatesh,Ashish Mahendran Kurapath,Tejas Melkote*

Main category: cs.CL

TL;DR: LLMs在算法推理方面存在系统性失败，称为"算法盲视"，即使拥有广泛知识也无法准确预测算法性能


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs展现出广泛的知识广度，但其对计算过程的推理能力仍不清楚。了解这一差距对依赖LLMs指导算法选择和部署的从业者至关重要

Method: 使用因果发现作为测试平台，评估八个前沿LLM，以大规模算法执行得出的真实数据为基准

Result: 发现系统性、近乎完全的失败：模型产生的置信区间远宽于真实区间，却仍无法在大多数情况下包含真实算法均值；多数模型表现比随机猜测更差，最佳模型的边际超随机表现最符合基准记忆而非原则性推理

Conclusion: 这种失败被称为"算法盲视"，反映了关于算法的陈述性知识与校准的程序性预测之间的根本差距

Abstract: Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.

</details>


### [42] [MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models](https://arxiv.org/abs/2602.21950)
*Boqi Chen,Xudong Liu,Jiachuan Peng,Marianne Frey-Marti,Bang Zheng,Kyle Lam,Lin Li,Jianing Qiu*

Main category: cs.CL

TL;DR: MEDSYN是一个多语言多模态临床复杂病例基准测试，包含多达7种视觉临床证据类型，评估MLLMs在鉴别诊断生成和最终诊断选择上的表现，发现MLLMs在异构证据类型合成方面存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分捕捉真实世界的临床复杂性，需要更全面的评估框架来测试多模态大语言模型在复杂临床场景中的表现。

Method: 引入MEDSYN基准测试，包含多语言多模态的复杂临床病例，每个病例最多有7种不同类型的视觉临床证据。评估18个MLLMs在鉴别诊断生成和最终诊断选择上的表现，并引入证据敏感性指标量化跨模态证据利用差距。

Result: 顶级模型在鉴别诊断生成上常能匹配甚至超越人类专家，但所有MLLMs在鉴别诊断与最终诊断之间的性能差距远大于专家临床医生。研究发现MLLMs过度依赖区分性较差的文本证据（如病史），并存在跨模态证据利用差距。证据敏感性指标显示较小的差距与更高的诊断准确性相关。

Conclusion: MLLMs在异构临床证据类型合成方面存在系统性缺陷，证据敏感性指标可用于指导干预措施提升模型性能。该研究为改进医疗MLLMs提供了重要见解和评估工具。

Abstract: Multimodal large language models (MLLMs) have shown great potential in medical applications, yet existing benchmarks inadequately capture real-world clinical complexity. We introduce MEDSYN, a multilingual, multimodal benchmark of highly complex clinical cases with up to 7 distinct visual clinical evidence (CE) types per case. Mirroring clinical workflow, we evaluate 18 MLLMs on differential diagnosis (DDx) generation and final diagnosis (FDx) selection. While top models often match or even outperform human experts on DDx generation, all MLLMs exhibit a much larger DDx--FDx performance gap compared to expert clinicians, indicating a failure mode in synthesis of heterogeneous CE types. Ablations attribute this failure to (i) overreliance on less discriminative textual CE ($\it{e.g.}$, medical history) and (ii) a cross-modal CE utilization gap. We introduce Evidence Sensitivity to quantify the latter and show that a smaller gap correlates with higher diagnostic accuracy. Finally, we demonstrate how it can be used to guide interventions to improve model performance. We will open-source our benchmark and code.

</details>


### [43] [RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning](https://arxiv.org/abs/2602.21951)
*Bo Xue,Yuan Jin,Luoyi Fu,Jiaxin Ding,Xinbing Wang*

Main category: cs.CL

TL;DR: RADAR将知识图谱推理从生成式模式匹配重构为判别式关系推理，通过强化学习实现实体可分性，直接在表示空间进行推理以避免幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的知识图谱推理方法倾向于记忆表面共现模式而非学习真正的关系语义，限制了分布外泛化能力。生成式范式容易导致幻觉问题。

Method: 将KGR重新定义为判别式实体选择任务，使用强化学习强制实现相对实体可分性（超越词元似然模仿）。利用这种可分性，推理直接在表示空间进行，确保与判别式优化的一致性。

Result: 在四个基准测试中，RADAR在链接预测和三重分类任务上相对于强LLM基线实现了5-6%的相对提升，中间表示的任务相关互信息增加了62.9%，表明更鲁棒和可迁移的关系推理能力。

Conclusion: RADAR通过从生成式到判别式的范式转变，解决了LLM在知识图谱推理中的表面共现记忆问题，实现了更鲁棒的关系语义学习和更好的泛化能力。

Abstract: Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.

</details>


### [44] [CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models](https://arxiv.org/abs/2602.21978)
*Miyu Oba,Saku Sugawara*

Main category: cs.CL

TL;DR: CxMP基准测试基于构式语法评估语言模型对构式（形式-意义配对）的理解能力，发现大型语言模型在句法能力早期出现，但对构式的理解发展缓慢且有限。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注语法可接受性判断，而语言模型对通过语法形式传达意义的理解能力研究不足。需要评估模型是否能解释构式所隐含的语义关系。

Method: 基于构式语法理论，开发了CxMP基准测试，采用受控最小对设计，涵盖九种构式类型（包括let-alone、致使运动、双及物等构式），评估模型对构式语义关系的解释能力。

Result: 结果显示，句法能力在模型早期就出现，但对构式的理解发展更为缓慢，即使在大型语言模型中仍然有限。CxMP揭示了语言模型在整合形式与意义方面存在持续差距。

Conclusion: CxMP为研究语言模型中的构式理解和学习轨迹提供了框架，揭示了语言模型在形式-意义整合方面的局限性，为未来改进提供了方向。

Abstract: Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.

</details>


### [45] [A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT](https://arxiv.org/abs/2602.22014)
*Louis Estève,Christophe Servan,Thomas Lavergne,Agata Savary*

Main category: cs.CL

TL;DR: 研究探讨多样性对ModernBERT预训练的影响，通过多样性驱动的采样算法减少预训练数据集规模，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的transformer模型（如ModernBERT）使用基于规模而非多样性的超大预训练数据集，需要研究多样性对预训练的影响，旨在减少数据集规模的同时保持可比性能。

Method: 采用多样性驱动的采样算法，比较不同采样方法，选择最佳方案。使用多样性驱动数据集（1.5亿词元）与随机采样数据集（24亿词元）进行对比实验。

Result: 多样性驱动采样在某些任务上比同等规模的随机采样数据集性能提升10分；使用1.5亿词元多样性数据集预训练483小时的模型，与使用24亿词元随机数据集预训练1775小时的模型性能相当。

Conclusion: 多样性驱动的数据采样能显著减少预训练数据集规模和训练时间，同时保持或提升模型性能，为高效预训练提供了新方向。

Abstract: Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.

</details>


### [46] [DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain](https://arxiv.org/abs/2602.22045)
*Walter Hernandez Cruz,Peter Devine,Nikhil Vadgama,Paolo Tasca,Jiahua Xu*

Main category: cs.CL

TL;DR: DLT-Corpus是迄今为止最大的分布式账本技术领域特定文本集合，包含29.8亿个token和2212万份文档，涵盖科学文献、专利和社交媒体数据，填补了该领域NLP资源的空白。


<details>
  <summary>Details</summary>
Motivation: 现有DLT领域的NLP资源主要局限于加密货币价格预测和智能合约，缺乏对领域特定语言的深入探索，而该领域拥有约3万亿美元市值和快速技术演进，需要更全面的文本资源支持研究。

Method: 构建了包含三个来源的语料库：37,440篇科学文献、49,023项USPTO专利和2200万条社交媒体帖子。基于此语料库分析了技术出现模式和市场创新相关性，并开发了领域适应的LedgerBERT模型。

Result: 技术遵循从科学文献到专利再到社交媒体的传统技术转移模式；社交媒体情绪即使在加密货币寒冬期仍保持极度看涨；科学和专利活动独立于市场波动，与整体市场扩张形成良性循环。

Conclusion: DLT-Corpus填补了领域特定NLP资源的空白，揭示了DLT技术发展的独特模式：研究先于并促进经济增长，而经济增长又进一步资助创新。公开了完整语料库、LedgerBERT模型和相关工具。

Abstract: We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.
  We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.
  We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.

</details>


### [47] [Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference](https://arxiv.org/abs/2602.22090)
*Bo-Wei Chen,Chung-Chi Chen,An-Zi Yen*

Main category: cs.CL

TL;DR: 提出基于置信度的动态模型选择策略，在保持大模型精度的同时减少20-40%计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能随规模提升但计算成本高昂，需要平衡精度与效率的解决方案

Method: 置信度驱动策略：评估模型处理任务的置信度和响应准确性，将高置信度任务保留，复杂不确定任务委托给更大模型

Result: 在MMLU基准上达到最大模型相当精度，计算成本减少20-40%；GPT-4o API调用token使用减少约60%

Conclusion: 置信度模型选择策略能显著提升LLM部署效率，特别适用于资源受限环境和商业API应用

Abstract: Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\% to 40\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.

</details>


### [48] [IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages](https://arxiv.org/abs/2602.22125)
*Thanmay Jayakumar,Mohammed Safi Ur Rahman Khan,Raj Dabre,Ratish Puduppully,Anoop Kunchukuttan*

Main category: cs.CL

TL;DR: IndicIFEval：首个针对14种印度语言的大语言模型指令遵循基准，包含自动可验证的规则指令，评估约束生成能力


<details>
  <summary>Details</summary>
Motivation: 当前指令遵循基准主要集中于英语，缺乏对印度语言使用者的评估，存在关键评估缺口

Method: 构建包含两种互补子集的基准：IndicIFEval-Ground（从IFEval翻译并本地化的提示）和IndicIFEval-Ground（基于本地内容合成的指令），每种语言约800个人工验证示例

Result: 模型在格式约束方面表现良好，但在词汇和跨语言任务上显著困难；尽管高资源语言有进步，但整个印度语言家族的指令遵循能力仍远落后于英语

Conclusion: 需要更多关注印度语言的指令遵循能力，发布IndicIFEval基准和评估脚本以支持多语言约束生成研究

Abstract: Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).

</details>


### [49] [Dynamic Personality Adaptation in Large Language Models via State Machines](https://arxiv.org/abs/2602.22157)
*Leon Pielage,Ole Hätscher,Mitja Back,Bernhard Marschall,Benjamin Risse*

Main category: cs.CL

TL;DR: 提出模型无关的动态人格模拟框架，使用状态机表示潜在人格状态，通过对话上下文动态调整转换概率，在医学教育场景中实现人格自适应交互


<details>
  <summary>Details</summary>
Motivation: 大型语言模型无法根据对话动态调整人格表达，这限制了它们在复杂交互场景中的表现，需要开发能够动态适应的人格模拟系统

Method: 提出模型无关的动态人格模拟框架：1) 使用状态机表示潜在人格状态，转换概率根据对话上下文动态调整；2) 模块化的人格评分管道，沿潜在轴评估对话，独立于具体人格模型、维度、转换机制或LLM；3) 评分作为动态状态变量，系统性地重新配置系统提示，引导行为对齐

Result: 在医学教育场景中操作化人际环状模型，系统成功适应用户输入调整人格状态，并影响用户行为，促进降级训练；评分管道使用轻量级微调分类器时仍保持可比精度

Conclusion: 证明了模块化、人格自适应架构在教育、客户支持和更广泛人机交互中的可行性，为动态人格模拟提供了可扩展的解决方案

Abstract: The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.

</details>


### [50] [DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs](https://arxiv.org/abs/2602.22175)
*Xi Ye,Wuwei Zhang,Fangcong Yin,Howard Yen,Danqi Chen*

Main category: cs.CL

TL;DR: DySCO是一种无需训练的解码算法，通过检索头动态调整注意力权重，提升语言模型在长上下文推理中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现代语言模型支持越来越长的上下文窗口，但随着输入长度增加，模型准确性往往会下降。模型在解码过程中难以保持注意力与最相关上下文的对齐。

Method: DySCO利用检索头（专门用于长上下文检索的注意力头子集）在每个解码步骤识别任务相关token，并显式地提升它们的权重。该方法动态调整生成过程中的注意力，更好地利用相关上下文，无需训练即可直接应用于现成的语言模型。

Result: 在多个指令微调和推理模型上，DySCO在具有挑战性的长上下文推理基准测试中持续提升性能，在128K上下文长度下，MRCR和LongBenchV2上获得高达25%的相对增益，仅需适度的额外计算开销。

Conclusion: 动态注意力重新缩放和检索头引导的选择对于方法有效性都很重要，同时为解码时注意力行为提供了可解释性见解。DySCO是一种有效的训练免费方法，可提升语言模型的长上下文推理能力。

Abstract: Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.

</details>


### [51] [Improving Parametric Knowledge Access in Reasoning Language Models](https://arxiv.org/abs/2602.22193)
*Melody Ma,John Hewitt*

Main category: cs.CL

TL;DR: 研究发现语言模型在访问自身参数中的世界知识时，通过"逐步思考"提示能显著提升知识回忆能力，但数学推理能力不变。通过基于世界知识问答的强化学习训练，模型在多个知识问答数据集上性能得到提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索语言模型如何更好地访问存储在参数中的世界知识。虽然推理语言模型通过强化学习训练在数学等任务上能生成推理轨迹，但它们可能不擅长为访问自身世界知识而进行推理。研究发现模型默认不会生成最佳的世界知识推理。

Method: 首先发现添加简单的"逐步思考"提示能显著改善知识回忆但数学推理不变。基于此，提出使用世界知识问答作为可验证奖励，通过强化学习训练模型在其参数知识上进行推理。在TriviaQA数据集上进行强化学习训练。

Result: 在TriviaQA上性能提升9.9%，在Natural Questions、HotpotQA、SimpleQA和StrategyQA上分别提升4.2%、2.1%、0.6%和3.0%。研究表明推理模型在参数知识访问方面未充分优化，但可以通过训练显著改善。

Conclusion: 推理模型在访问其参数化世界知识方面未得到充分优化，但可以通过简单的训练方法显著改善推理能力。通过基于世界知识问答的强化学习训练，模型能够更好地利用自身存储的知识进行推理。

Abstract: We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple "think step-by-step" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.

</details>


### [52] [SumTablets: A Transliteration Dataset of Sumerian Tablets](https://arxiv.org/abs/2602.22200)
*Cole Simmons,Richard Diehl Martinez,Dan Jurafsky*

Main category: cs.CL

TL;DR: SumTablets数据集：将91,606块苏美尔楔形文字泥板的Unicode表示与Oracc发布的音译文本配对，填补了楔形文字与音译配对数据集的空白，支持NLP方法应用于苏美尔音译任务。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量苏美尔音译文本在线发布（如ETCSL、CDLI、Oracc项目），但缺乏将音译文本与泥板楔形文字数字表示配对的综合数据集，阻碍了现代自然语言处理方法在苏美尔音译任务中的应用。

Method: 1. 预处理和标准化Oracc音译文本；2. 将每个读音映射回源字符的Unicode表示；3. 通过特殊标记保留平行结构信息（如表面、换行、破损片段）；4. 构建包含91,606块泥板（总计6,970,407个字符）的数据集；5. 实现并评估两种音译基线方法：加权采样和自回归语言模型微调。

Result: 1. 发布了SumTablets数据集（Hugging Face，CC BY 4.0许可）和开源数据准备代码；2. 微调的语言模型在字符级F分数（chrF）上达到97.55的平均分，展示了基于transformer的音译模型在帮助专家快速验证生成音译方面的潜力。

Conclusion: SumTablets填补了苏美尔楔形文字与音译配对数据集的空白，为应用现代NLP方法提供了基础。实验表明基于transformer的音译模型具有实用价值，能够帮助专家从手动逐块音译转向快速验证生成音译，提高研究效率。

Abstract: Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.
  To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.
  Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [53] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本文对软集理论及其扩展进行了综述性概述，涵盖核心定义、代表性构造和当前发展方向


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，通过为每个属性分配给定论域的子集来结构化表示不确定性。该理论已扩展到多个变体并与其他数学领域连接，需要系统性的综述来总结发展现状

Method: 采用综述性方法，系统性地概述软集理论及其主要扩展，包括超软集、超超软集、树软集、双极软集和动态软集等变体，并展示与拓扑学和拟阵理论的连接

Result: 提供了软集理论及其扩展的全面综述，突出了核心定义、代表性构造和当前研究方向，为相关领域研究者提供了系统的理论框架和发展脉络

Conclusion: 软集理论已发展成为一个丰富的研究领域，通过多种扩展和与其他数学分支的连接，为不确定性建模和参数化决策提供了强大的理论工具，本书的综述有助于推动该领域的进一步发展

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [54] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT：用于地球科学数据自主发现和分析的分层多智能体框架


<details>
  <summary>Details</summary>
Motivation: 地球科学数据快速增长但利用率低，PANGAEA等存储库中大量数据集未被充分利用，限制了数据可重用性

Method: 提出PANGAEA-GPT分层多智能体框架，采用集中式Supervisor-Worker拓扑结构，具有数据类型感知路由、沙盒确定性代码执行和通过执行反馈进行自校正功能

Result: 通过物理海洋学和生态学用例场景，证明系统能够以最少人工干预执行复杂的多步骤工作流程

Conclusion: 该框架提供了一种通过协调智能体工作流程查询和分析异构存储库数据的方法论

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [55] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 该论文提出了ARLArena框架和SAMPO方法，用于解决Agentic强化学习（ARL）中的训练不稳定问题，通过系统化分析训练稳定性并提供稳定优化方案。


<details>
  <summary>Details</summary>
Motivation: Agentic强化学习（ARL）在解决复杂多步交互任务方面显示出潜力，但训练过程高度不稳定，经常导致训练崩溃。这种不稳定性限制了其在更大环境和更长交互视野中的可扩展性，也制约了算法设计选择的系统性探索。

Method: 首先提出ARLArena框架，构建干净标准化的测试平台。然后将策略梯度分解为四个核心设计维度，评估每个维度的性能和稳定性。基于此细粒度分析，提出SAMPO（稳定Agentic策略优化方法），旨在缓解ARL中的主要不稳定源。

Result: SAMPO在多样化的Agentic任务中实现了持续稳定的训练和强大的性能表现。ARLArena框架提供了受控可复现的设置来系统分析训练稳定性。

Conclusion: 本研究为ARL提供了统一的策略梯度视角，并为构建稳定可复现的基于LLM的Agent训练流程提供了实用指导。

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>


### [56] [The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems](https://arxiv.org/abs/2602.21745)
*Hyo Jin Kim*

Main category: cs.AI

TL;DR: ASIR勇气模型是一个相动力学框架，将真相披露重新定义为状态转换而非人格特质，适用于人类和AI系统在风险下的真相揭示行为。


<details>
  <summary>Details</summary>
Motivation: 传统上勇气常被视为固定的人格特质，但作者认为真相披露行为实际上是一个动态的状态转换过程。该模型旨在为人类在不对称风险下的真相披露和AI系统在政策约束下的输出行为提供统一的理论框架，解释两者在结构上的相似性。

Method: 提出相动力学框架，将真相披露建模为从抑制状态(S0)到表达状态(S1)的相变过程。使用不等式 λ(1+γ)+ψ > θ+φ 描述状态转换条件，其中λ代表基线开放性，γ为关系放大因子，ψ为累积内部压力，θ和φ为转换成本。该框架还包含反馈扩展，模拟转换结果如何递归地重新校准系统参数。

Result: 该模型成功地将人类真相披露行为（在不对称风险下）和AI系统输出行为（在政策约束和一致性过滤下）统一到同一个相动力学架构中。它解释了人类在压力下的沉默和AI偏好驱动下的失真都是相空间中相互作用力的几何结果，而非系统意图的表现。

Conclusion: ASIR勇气模型提供了一个形式化的视角，将勇气和一致性重新框架为受限相空间中的共享动力学结构。该模型表明，人类和人工系统中的真相披露行为都可以理解为相变过程，为跨系统研究风险下的真相揭示提供了统一的理论基础。

Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.
  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.
  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.

</details>


### [57] [fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation](https://arxiv.org/abs/2602.21746)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: fEDM+扩展了原有的模糊伦理决策框架，通过添加可解释性模块和多元语义验证框架，解决了原模型在原则性可解释性和伦理多元主义下的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 原fEDM框架虽然确保了形式正确性和决策一致性，但未能充分解决两个关键挑战：决策的原则性可解释性，以及在伦理多元主义下的鲁棒性。需要增强透明度和对多元伦理视角的适应性。

Method: 1. 引入可解释性与可追溯性模块(ETM)，将伦理决策规则与底层道德原则显式关联，为每个推荐行动计算加权原则贡献度。2. 用多元语义验证框架替代单参照验证，针对多个利益相关者参照进行评估，每个参照编码不同的原则优先级和风险容忍度。

Result: 扩展后的fEDM+框架保持了形式可验证性，同时实现了增强的可解释性和利益相关者感知的验证。能够提供透明、可审计的解释，展示决策依据和原则基础，并能正式表示原则性分歧而非压制。

Conclusion: fEDM+作为伦理敏感AI系统的监督和治理层是合适的，它保留了形式可验证性，同时实现了增强的可解释性和利益相关者感知的验证，能够处理伦理多元主义并提高上下文敏感性。

Abstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.

</details>


### [58] [Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem](https://arxiv.org/abs/2602.21814)
*Heejin Jo*

Main category: cs.AI

TL;DR: STAR推理框架将洗车问题准确率从0%提升至85%，结合用户画像和RAG达到100%准确率，表明结构化推理比上下文注入更重要


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要隐式物理约束推理的"洗车问题"上持续失败，研究旨在探索生产系统中哪些提示架构层能够实现正确推理

Method: 使用Claude 3.5 Sonnet进行变量隔离研究（n=20/条件，6个条件，共120个试验），控制超参数（温度0.7，top_p 1.0），测试不同提示架构层：基础提示、STAR框架、用户画像上下文、RAG上下文等组合

Result: STAR推理框架单独将准确率从0%提升至85%（p=0.001，Fisher精确检验，比值比13.22）；添加用户画像上下文再提升10个百分点；RAG上下文贡献额外5个百分点；完整堆栈条件下达到100%准确率

Conclusion: 结构化推理支架（特别是推理前的强制目标表达）对于隐式约束推理任务的重要性远超过上下文注入，为改进LLM物理推理能力提供了实用方法

Abstract: Large language models consistently fail the "car wash problem," a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.

</details>


### [59] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出强化学习方法，联合优化分解质量和验证器对齐，提升复杂声明验证性能


<details>
  <summary>Details</summary>
Motivation: 现有方法在将句子分解为可验证子声明时，难以协调分解质量与验证性能的对齐问题

Method: 使用Group Relative Policy Optimization强化学习框架，结合结构化顺序推理、教师蒸馏示例的监督微调，以及平衡格式合规性、验证器对齐和分解质量的多目标奖励

Result: 在六个评估场景中，训练的8B分解器将下游验证性能提升至71.75% macro-F1，优于基于提示的方法和现有RL方法，人类评估确认生成的子声明质量高

Conclusion: 该框架使较小语言模型能够通过联合优化验证准确性和分解质量，实现最先进的声明验证性能

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [60] [ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](https://arxiv.org/abs/2602.21858)
*Dezhi Kong,Zhengzhao Feng,Qiliang Liang,Hao Wang,Haofei Sun,Changpeng Yang,Yang Li,Peng Zhou,Shuai Nie,Hongzhen Wang,Linfeng Zhou,Hao Jia,Jiaming Xu,Runyu Shi,Ying Huang*

Main category: cs.AI

TL;DR: ProactiveMobile是一个用于评估移动智能体主动智能能力的基准测试，包含3,660个实例、14个场景和63个API函数，旨在解决当前多模态大语言模型在主动智能方面的评估瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型主要局限于被动执行用户命令的反应式范式，而主动智能（智能体自主预测需求并启动行动）是移动智能体的下一个前沿。然而，该领域的发展受到缺乏能够应对现实世界复杂性并支持客观、可执行评估的基准测试的严重制约。

Method: 1. 将主动任务形式化为基于设备上下文信号的四个维度推断潜在用户意图；2. 从包含63个API的综合函数池中生成可执行函数序列；3. 构建包含3,660个实例、14个场景的基准测试，采用多答案标注以应对现实世界复杂性；4. 由30名专家团队进行最终审核，确保事实准确性、逻辑一致性和行动可行性。

Result: 微调的Qwen2.5-VL-7B-Instruct模型在基准测试中取得了19.15%的成功率，优于o1（15.71%）和GPT-5（7.39%）。这表明主动智能是当前MLLMs普遍缺乏但可学习的关键能力，凸显了所提基准测试对主动智能评估的重要性。

Conclusion: ProactiveMobile基准测试为移动智能体主动智能研究提供了系统化的评估框架。实验结果证实主动智能是当前MLLMs的薄弱环节但可通过学习获得，该基准将推动主动智能领域的发展，并为未来研究提供重要的评估工具。

Abstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.

</details>


### [61] [Semantic Partial Grounding via LLMs](https://arxiv.org/abs/2602.22067)
*Giuseppe Canonaco,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: SPG-LLM使用大语言模型分析PDDL描述，在规划前识别潜在无关的对象、动作和谓词，显著减少基础化任务规模，在七个难基础化基准测试中实现更快的基础化。


<details>
  <summary>Details</summary>
Motivation: 经典规划中的基础化步骤常因任务规模增大导致基础化动作和原子呈指数增长而成为计算瓶颈。现有部分基础化方法主要依赖关系特征或学习嵌入，未能充分利用PDDL描述中的文本和结构线索。

Method: SPG-LLM利用大语言模型分析领域和问题文件，在基础化前启发式识别潜在无关的对象、动作和谓词，从而显著减少基础化任务的规模。

Result: 在七个难基础化基准测试中，SPG-LLM实现了更快的基础化（通常快几个数量级），在某些领域还提供了可比或更好的规划成本。

Conclusion: 利用大语言模型分析PDDL的文本和结构信息可以有效识别无关元素，显著减少基础化规模并加速规划过程，同时保持规划质量。

Abstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.

</details>


### [62] [Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning](https://arxiv.org/abs/2602.22094)
*Nguyen Cong Nhat Le,John G. Rogers,Claire N. Bonial,Neil T. Dantam*

Main category: cs.AI

TL;DR: 提出基于Petri网可达性松弛的方法，用于鲁棒的约束不变式合成、高效的目标不可达检测和有用的不可行性解释，支持目标和约束的增量更新。


<details>
  <summary>Details</summary>
Motivation: 现实中的规划问题常常因情境变化或认知更新而需要调整计划，有时甚至不存在可行计划。传统规划方法主要关注可行情况下的高效一次性规划，而缺乏对领域更新和不可行性检测的支持。

Method: 采用Petri网可达性松弛技术，实现鲁棒的约束不变式合成；利用增量约束求解器支持目标和约束的增量更新；通过可达性分析检测目标不可达情况并提供解释。

Result: 与基线方法相比，系统生成相当数量的约束不变式，检测到最多2倍的不可行情况，在一次性规划中表现相当，在顺序规划更新中优于基线方法。

Conclusion: 提出的Petri网可达性松弛方法能够有效支持规划问题的动态更新、不可行性检测和解释，为实际应用中频繁变化的规划需求提供了实用解决方案。

Abstract: Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [63] [Evaluating the Indistinguishability of Logic Locking using K-Cut Enumeration and Boolean Matching](https://arxiv.org/abs/2602.21386)
*Jonathan Cruz,Jason Hamlet*

Main category: cs.CR

TL;DR: 该论文提出了一种基于k-cut分布比较的逻辑锁定不可区分性评估方法，并在多种逻辑锁定技术上验证了其有效性，发现现有锁定方案无法提供真正的不可区分性。


<details>
  <summary>Details</summary>
Motivation: 逻辑锁定作为半导体IP保护方案在学术界受到关注，但缺乏能够抵御已知威胁的可行方案。由于缺乏严格性，逻辑锁定防御措施往往寿命短暂，这对于可能部署数十年的关键系统硬件安全来说是不可接受的风险。研究人员试图将密码学中的不可区分性概念映射到逻辑锁定中，因为不可区分性提供了强大的安全保证。

Method: 提出了一种基于比较k-cut分布的新评估方法，类似于与子函数库进行比较。该方法用于分析逻辑锁定技术的不可区分性，并在多种不同类别的逻辑锁定技术上进行了评估。

Result: 评估结果显示，即使在存在重综合的情况下，该方法在正确识别哪个设计被锁定方面达到了高达92%的平均准确率，这表明被评估的锁定方案无法提供不可区分性。

Conclusion: 当前评估的逻辑锁定技术无法提供真正的不可区分性安全保证，需要更严格的评估方法和更强的安全方案来满足关键系统硬件安全的长寿命需求。

Abstract: Logic locking as a solution for semiconductor intellectual property (IP) confidentiality has received considerable attention in academia, but has yet to produce a viable solution to protect against known threats. In part due to a lack of rigor, logic locking defenses have been historically short-lived, which is an unacceptable risk for hardware-based security solutions for critical systems that may be fielded for decades. Researchers have worked to map the concept of cryptographic indistinguishability to logic locking, as indistinguishability provides strong security guarantees. In an effort to bridge theory and practice, we highlight recent efforts that can be used to analyze the indistinguishability of logic locking techniques, and propose a new method of evaluation based on comparing distributions of $k$-cuts, which is akin to comparing against a library of sub-functions. We evaluate our approach on several different classes of logic locking and show up to 92% average accuracy in correctly identifying which design was locked, even in the presence of resynthesis, suggesting that the evaluated locks do not provide indistinguishability.

</details>


### [64] [Regular Expression Denial of Service Induced by Backreferences](https://arxiv.org/abs/2602.21459)
*Yichen Liu,Berk Çakar,Aman Agrawal,Minseok Seo,James C. Davis,Dongyoon Lee*

Main category: cs.CR

TL;DR: 首次系统研究正则表达式反向引用中的拒绝服务漏洞，提出2PMFA模型识别三类漏洞模式，在Snort规则集中发现45个未知漏洞并实现实际攻击


<details>
  <summary>Details</summary>
Motivation: 现有检测器在线性歧义情况下无法识别反向引用导致的超线性回溯运行时漏洞，需要系统研究正则表达式反向引用中的拒绝服务安全问题

Method: 提出两阶段内存自动机（2PMFA）模型精确捕获REwB语义，推导反向引用引发超线性回溯的必要条件，识别三类漏洞模式，开发检测和攻击构建算法

Result: 在Snort入侵检测规则集中发现45个先前未知的REwB漏洞（二次或更差运行时），实现对Snort的实际攻击：规则评估延迟0.6-1.2秒，通过触发PCRE匹配限制绕过警报

Conclusion: 反向引用即使在线性歧义情况下也能导致超线性回溯，现有检测器存在盲点，提出的2PMFA模型和检测算法能有效识别此类漏洞，对安全关键系统具有重要影响

Abstract: This paper presents the first systematic study of denial-of-service vulnerabilities in Regular Expressions with Backreferences (REwB). We introduce the Two-Phase Memory Automaton (2PMFA), an automaton model that precisely captures REwB semantics. Using this model, we derive necessary conditions under which backreferences induce super-linear backtracking runtime, even when sink ambiguity is linear -- a regime where existing detectors report no vulnerability. Based on these conditions, we identify three vulnerability patterns, develop detection and attack-construction algorithms, and validate them in practice. Using the Snort intrusion detection ruleset, our evaluation identifies 45 previously unknown REwB vulnerabilities with quadratic or worse runtime. We further demonstrate practical exploits against Snort, including slowing rule evaluation by 0.6-1.2 seconds and bypassing alerts by triggering PCRE's matching limit.

</details>


### [65] [Quantum Attacks Targeting Nuclear Power Plants: Threat Analysis, Defense and Mitigation Strategies](https://arxiv.org/abs/2602.21524)
*Yaser Baseri,Edward Waller*

Main category: cs.CR

TL;DR: 该论文提出了一种针对工业控制系统（ICS）和运营技术（OT）的量子韧性取证优先框架，特别关注核电站等关键基础设施，分析了量子计算对加密基础和取证完整性的威胁，并通过案例研究和风险模型展示了攻击风险，提出了向后量子密码学迁移的防御策略。


<details>
  <summary>Details</summary>
Motivation: 密码学相关量子计算机（CRQCs）的出现对工业控制系统（ICS）和运营技术（OT）的取证完整性和操作安全构成了根本性威胁，特别是在核电站等高后果环境中。当前系统面临"现在收集、以后解密"（HNDL）攻击的风险，可能破坏加密基础、损害证据可采性，并导致无法解决的取证悖论。

Method: 采用系统性的量子威胁分析方法，基于普渡架构（L0-L5）分析威胁场景；通过两个详细案例研究（Quantum Scar和Quantum Dawn）展示多阶段攻击方法；使用概率风险模型评估攻击成功概率；提出并验证分阶段的深度防御向后量子密码学（PQC）迁移路径，整合混合密钥交换、加密多样性、安全时间同步和抗侧信道攻击实现。

Result: 概率风险建模显示，在当前防御措施下，目标设施的攻击成功概率高达78%；案例研究展示了国家级别对手如何利用加密单一性和OT长生命周期来破坏安全系统并制造无法解决的取证悖论；提出的量子韧性框架与ISA/IEC 62443和NIST标准保持一致。

Conclusion: 如果不紧急采用量子韧性控制措施，物理安全系统和数字取证证据的完整性将面临严重且不可逆转的风险。论文强调需要立即采取行动，实施分阶段的向后量子密码学迁移策略，以保护关键基础设施免受量子计算威胁。

Abstract: The advent of Cryptographically Relevant Quantum Computers (CRQCs) presents a fundamental and existential threat to the forensic integrity and operational safety of Industrial Control Systems (ICS) and Operational Technology (OT) in critical infrastructure. This paper introduces a novel, forensics-first framework for achieving quantum resilience in high-consequence environments, with a specific focus on nuclear power plants. We systematically analyze the quantum threat landscape across the Purdue architecture (L0-L5), detailing how Harvest-Now, Decrypt-Later (HNDL) campaigns, enabled by algorithms like Shor's, can retroactively compromise cryptographic foundations, undermine evidence admissibility, and facilitate sophisticated sabotage. Through two detailed case studies, \textsc{Quantum~Scar} and \textsc{Quantum~Dawn}, we demonstrate multi-phase attack methodologies where state-level adversaries exploit cryptographic monoculture and extended OT lifecycles to degrade safety systems while creating unsolvable forensic paradoxes. Our probabilistic risk modeling reveals alarming success probabilities (up to 78\% for targeted facilities under current defenses), underscoring the criticality of immediate action. In response, we propose and validate a phased, defense-in-depth migration path to Post-Quantum Cryptography (PQC), integrating hybrid key exchange, cryptographic diversity, secure time synchronization, and side-channel resistant implementations aligned with ISA/IEC 62443 and NIST standards. The paper concludes that without urgent adoption of quantum-resilient controls, the integrity of both physical safety systems and digital forensic evidence remains at severe and irreversible risk.

</details>


### [66] [TM-RUGPULL: A Temporary Sound, Multimodal Dataset for Early Detection of RUG Pulls Across the Tokenized Ecosystem](https://arxiv.org/abs/2602.21529)
*Fatemeh Shoaei,Mohammad Pishdar,Mozafar Bag-Mohammadi,Mojtaba Karami*

Main category: cs.CR

TL;DR: TM-RugPull是一个精心构建、防泄漏的数据集，包含1,028个代币项目，涵盖DeFi、模因币、NFT和名人主题代币，用于地毯式攻击的早期检测研究。


<details>
  <summary>Details</summary>
Motivation: 当前区块链地毯式攻击研究面临缺乏科学级数据集的挑战，现有资源存在时间数据泄漏、模态狭窄和标签模糊等问题，特别是在DeFi之外的领域。

Method: 构建TM-RugPull数据集，包含1,028个代币项目，严格实施时间卫生：所有特征（链上行为、智能合约元数据、OSINT信号）仅从项目生命周期的前半部分提取。标签基于法医报告和长寿标准，通过多专家共识验证。

Result: 创建了一个防泄漏、多模态的数据集，支持对地毯式攻击动态进行因果有效的分析，并为可复现的欺诈检测研究建立了新基准。

Conclusion: TM-RugPull数据集解决了区块链地毯式攻击研究中的数据质量问题，为早期检测提供了科学基础，推动了该领域研究的可复现性和可靠性。

Abstract: Rug-pull attacks pose a systemic threat across the blockchain ecosystem, yet research into early detection is hindered by the lack of scientific-grade datasets. Existing resources often suffer from temporal data leakage, narrow modality, and ambiguous labeling, particularly outside DeFi contexts. To address these limitations, we present TM-RugPull, a rigorously curated, leakage-resistant dataset of 1,028 token projects spanning DeFi, meme coins, NFTs, and celebrity-themed tokens. RugPull enforces strict temporal hygiene by extracting all features on chain behavior, smart contract metadata, and OSINT signals strictly from the first half of each project's lifespan. Labels are grounded in forensic reports and longevity criteria, verified through multi-expert consensus. This dataset enables causally valid, multimodal analysis of rug-pull dynamics and establishes a new benchmark for reproducible fraud detection research.

</details>


### [67] [Private and Robust Contribution Evaluation in Federated Learning](https://arxiv.org/abs/2602.21721)
*Delio Jaramillo Velez,Gergely Biczok,Alexandre Graell i Amat,Johan Ostman,Balazs Pejo*

Main category: cs.CR

TL;DR: 提出两种与安全聚合兼容的边际差异贡献评分方法，在保护隐私的同时实现公平的贡献评估


<details>
  <summary>Details</summary>
Motivation: 跨机构联邦学习中，安全聚合保护隐私但阻碍贡献评估，现有边际贡献方法（如Shapley值）与安全聚合不兼容，而实用替代方案（如留一法）粗糙且依赖自评估

Method: 引入两种边际差异贡献评分：Fair-Private满足标准公平公理，Everybody-Else消除自评估并提供抗操纵性；提供公平性、隐私性、鲁棒性和计算效率的理论保证

Result: 在多个医学图像数据集和CIFAR10上评估，新方法持续优于现有基线，更好地近似Shapley诱导的客户端排名，提升下游模型性能和异常行为检测

Conclusion: 公平性、隐私性、鲁棒性和实际效用可以在联邦贡献评估中同时实现，为真实世界跨机构部署提供原则性解决方案

Abstract: Cross-silo federated learning allows multiple organizations to collaboratively train machine learning models without sharing raw data, but client updates can still leak sensitive information through inference attacks. Secure aggregation protects privacy by hiding individual updates, yet it complicates contribution evaluation, which is critical for fair rewards and detecting low-quality or malicious participants. Existing marginal-contribution methods, such as the Shapley value, are incompatible with secure aggregation, and practical alternatives, such as Leave-One-Out, are crude and rely on self-evaluation.
  We introduce two marginal-difference contribution scores compatible with secure aggregation. Fair-Private satisfies standard fairness axioms, while Everybody-Else eliminates self-evaluation and provides resistance to manipulation, addressing a largely overlooked vulnerability. We provide theoretical guarantees for fairness, privacy, robustness, and computational efficiency, and evaluate our methods on multiple medical image datasets and CIFAR10 in cross-silo settings. Our scores consistently outperform existing baselines, better approximate Shapley-induced client rankings, and improve downstream model performance as well as misbehavior detection. These results demonstrate that fairness, privacy, robustness, and practical utility can be achieved jointly in federated contribution evaluation, offering a principled solution for real-world cross-silo deployments.

</details>


### [68] [Resilient Federated Chain: Transforming Blockchain Consensus into an Active Defense Layer for Federated Learning](https://arxiv.org/abs/2602.21841)
*Mario García-Márquez,Nuria Rodríguez-Barroso,M. Victoria Luzón,Francisco Herrera*

Main category: cs.CR

TL;DR: 论文提出Resilient Federated Chain (RFC)框架，将区块链与联邦学习结合，通过改造PoFL架构的Pooled Mining冗余机制作为主动防御层，增强对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL)作为构建可信AI的关键范式，虽然能实现隐私保护的分布式训练，但极易受到对抗攻击，损害模型完整性和数据机密性。传统数据检查方法与FL的分布式设计不兼容，而现有区块链与FL结合的研究对对抗攻击防御潜力探索不足。

Method: 提出RFC框架：1) 基于现有Proof of Federated Learning架构，将其Pooled Mining机制的冗余重新设计为主动防御层；2) 将主动防御层与鲁棒聚合规则结合；3) 在共识机制中引入灵活评估函数，实现针对不同攻击策略的自适应防御。

Result: 在图像分类任务上进行了广泛实验评估，涵盖多种对抗攻击场景。结果显示RFC相比基线方法显著提升了鲁棒性，为保护分布式学习环境提供了可行解决方案。

Conclusion: RFC框架通过区块链增强的联邦学习架构，有效提升了对抗攻击的防御能力，为构建更安全的分布式学习系统提供了新的技术路径。

Abstract: Federated Learning (FL) has emerged as a key paradigm for building Trustworthy AI systems by enabling privacy-preserving, decentralized model training. However, FL is highly susceptible to adversarial attacks that compromise model integrity and data confidentiality, a vulnerability exacerbated by the fact that conventional data inspection methods are incompatible with its decentralized design. While integrating FL with Blockchain technology has been proposed to address some limitations, its potential for mitigating adversarial attacks remains largely unexplored. This paper introduces Resilient Federated Chain (RFC), a novel blockchain-enabled FL framework designed specifically to enhance resilience against such threats. RFC builds upon the existing Proof of Federated Learning architecture by repurposing the redundancy of its Pooled Mining mechanism as an active defense layer that can be combined with robust aggregation rules. Furthermore, the framework introduces a flexible evaluation function in its consensus mechanism, allowing for adaptive defense against different attack strategies. Extensive experimental evaluation on image classification tasks under various adversarial scenarios, demonstrates that RFC significantly improves robustness compared to baseline methods, providing a viable solution for securing decentralized learning environments.

</details>


### [69] [APFuzz: Towards Automatic Greybox Protocol Fuzzing](https://arxiv.org/abs/2602.21892)
*Yu Wang,Yang Xiang,Chandra Thapa,Hajime Suzuki*

Main category: cs.CR

TL;DR: APFuzz是一个自动化的灰盒协议模糊测试工具，通过两阶段状态变量识别和基于大语言模型的字段级变异操作，提升协议模糊测试的智能性。


<details>
  <summary>Details</summary>
Motivation: 协议模糊测试中，状态模型和消息模型是核心组件，对测试效果有重要影响。现有灰盒协议模糊测试工具在状态模型准确性和消息模型智能性方面存在不足，需要更智能的方法来提升测试效率。

Method: APFuzz采用两阶段方法：1) 通过静态和动态分析自动识别状态变量，在模糊测试过程中推断准确的状态模型；2) 利用大语言模型实现消息结构感知，为二进制协议引入字段级变异操作。

Result: 在公开协议模糊测试基准上进行了广泛实验，将APFuzz与基线模糊测试工具AFLNET以及多个最先进的灰盒协议模糊测试工具进行了比较，验证了其有效性。

Conclusion: APFuzz通过创新的状态模型推断和基于大语言模型的消息结构感知，显著提升了灰盒协议模糊测试的智能性和测试效果，为协议实现的安全测试提供了更有效的工具。

Abstract: Greybox protocol fuzzing is a random testing approach for stateful protocol implementations, where the input is protocol messages generated from mutations of seeds, and the search in the input space is driven by the feedback on coverage of both code and state. State model and message model are the core components of communication protocols, which also have significant impacts on protocol fuzzing. In this work, we propose APFuzz (Automatic greybox Protocol Fuzzer) with novel designs to increase the smartness of greybox protocol fuzzers from the perspectives of both the state model and the message model. On the one hand, APFuzz employs a two-stage process of static and dynamic analysis to automatically identify state variables, which are then used to infer an accurate state model during fuzzing. On the other hand, APFuzz introduces field-level mutation operations for binary protocols, leveraging message structure awareness enabled by Large Language Models. We conduct extensive experiments on a public protocol fuzzing benchmark, comparing APFuzz with the baseline fuzzer AFLNET as well as several state-of-the-art greybox protocol fuzzers.

</details>


### [70] [A Critical Look into Threshold Homomorphic Encryption for Private Average Aggregation](https://arxiv.org/abs/2602.22037)
*Miguel Morona-Mínguez,Alberto Pedrouzo-Ulloa,Fernando Pérez-González*

Main category: cs.CR

TL;DR: 该论文调查了基于阈值RLWE的同态加密在联邦学习平均聚合中的应用，分析了主流库中阈值方案的安全漏洞，并评估了使用大方差模糊噪声作为对策的性能影响。


<details>
  <summary>Details</summary>
Motivation: 阈值同态加密（Threshold HE）非常适合实现联邦学习中的私有平均聚合操作，但近期研究发现主流HE库中的阈值方案在存在受限解密预言机时可能引入安全漏洞，需要研究有效的安全对策及其性能影响。

Method: 该研究调查了基于阈值RLWE的同态加密在联邦平均聚合中的应用，分析了阈值BFV和CKKS方案的性能，特别评估了使用大方差模糊噪声作为安全对策对系统性能的影响。

Result: 研究发现CKKS-based聚合与BFV-based解决方案性能相当，提供了阈值BFV和CKKS方案的详细比较，评估了模糊噪声对策的实际性能影响。

Conclusion: 阈值同态加密在联邦学习聚合中具有应用潜力，但需要关注安全漏洞问题；使用大方差模糊噪声作为对策是可行的，CKKS方案在性能上可与BFV方案相媲美。

Abstract: Threshold Homomorphic Encryption (Threshold HE) is a good fit for implementing private federated average aggregation, a key operation in Federated Learning (FL). Despite its potential, recent studies have shown that threshold schemes available in mainstream HE libraries can introduce unexpected security vulnerabilities if an adversary has access to a restricted decryption oracle. This oracle reflects the FL clients' capacity to collaboratively decrypt the aggregated result without knowing the secret key. This work surveys the use of threshold RLWE-based HE for federated average aggregation and examines the performance impact of using smudging noise with a large variance as a countermeasure. We provide a detailed comparison of threshold variants of BFV and CKKS, finding that CKKS-based aggregations perform comparably to BFV-based solutions.

</details>
